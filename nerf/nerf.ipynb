{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6135c0",
   "metadata": {},
   "source": [
    "# Neural Radiance Fields\n",
    "\n",
    "This notebook was written while referencing the original NeRF code so as to visualize step by step on how NeRF works. Some functions have been refactored for better understanding but as much as possible, none of the actual code was changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc70c7",
   "metadata": {},
   "source": [
    "## Attribution and Citation\n",
    "- Original paper: Mildenhall, Ben; Srinivasan, Pratul P.; Tancik, Matthew; Barron, Jonathan T.; Ramamoorthi, Ravi; Ng, Ren. “NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.” ECCV 2020. [arXiv:2003.08934](https://arxiv.org/abs/2003.08934)\n",
    "- Reference code: [bmild/nerf](https://github.com/bmild/nerf) (MIT License). Copyright © 2020 Ben Mildenhall.\n",
    "\n",
    "```bibtex\n",
    "@inproceedings{mildenhall2020nerf,\n",
    "  title     = {NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},\n",
    "  author    = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},\n",
    "  booktitle = {European Conference on Computer Vision (ECCV)},\n",
    "  year      = {2020}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc42dfb",
   "metadata": {},
   "source": [
    "## Import Dependencies and Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c328110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Third party libraries\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper libraries\n",
    "from embedder import *\n",
    "from nerf_helpers import *\n",
    "import utils\n",
    "\n",
    "# Loaders\n",
    "from load_llff import *\n",
    "from load_blender import *\n",
    "from load_deepvoxels import * \n",
    "from load_LINEMOD import *\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "DEBUG = False\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82faedd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3d9eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeted yaml folder: yaml\\ship_blender200k_fullres_higher_samples\n",
      "Loading configuration from yaml\\ship_blender200k_fullres_higher_samples\n",
      "Configuration validation passed! Arguments are valid and correctly set.\n",
      "Experiment name: ship_blender200k_fullres_higher_samples\n"
     ]
    }
   ],
   "source": [
    "# Load experiment config from yaml\n",
    "EXPERIMENT_NAME = \"ship_blender200k_fullres_higher_samples\"\n",
    "folder_path = os.path.join(\"yaml\", EXPERIMENT_NAME)\n",
    "print(f\"Targeted yaml folder: {folder_path}\")\n",
    "\n",
    "# Load the yaml data for use later in terms of args.\n",
    "args = utils.load_or_create_config(folder_path)\n",
    "\n",
    "print(f\"Experiment name: {args[\"expname\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfcaacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted args dict to AttrDict (dot-access enabled). Example: args.expname -> ship_blender200k_fullres_higher_samples\n"
     ]
    }
   ],
   "source": [
    "# Convert dict-style args to dot-access with recursive wrapping\n",
    "class AttrDict(dict):\n",
    "    \"\"\"Dictionary with attribute-style access that recursively wraps nested dicts/lists.\n",
    "\n",
    "    Example:\n",
    "        d = AttrDict.from_obj({\"a\": {\"b\": 1}, \"c\": [{\"d\": 2}]})\n",
    "        d.a.b == 1\n",
    "        d.c[0].d == 2\n",
    "        d.new_key = 3  # also writes to the underlying dict\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError as e:\n",
    "            raise AttributeError(f\"No such attribute: {name}\") from e\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    @classmethod\n",
    "    def from_obj(cls, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return cls({k: cls.from_obj(v) for k, v in obj.items()})\n",
    "        if isinstance(obj, list):\n",
    "            return [cls.from_obj(v) for v in obj]\n",
    "        return obj\n",
    "\n",
    "# If args came from YAML as a plain dict, wrap it for dot access\n",
    "try:\n",
    "    if isinstance(args, dict):\n",
    "        args = AttrDict.from_obj(args)\n",
    "        print(\"Converted args dict to AttrDict (dot-access enabled). Example: args.expname ->\", args.expname)\n",
    "except NameError:\n",
    "    # If this cell runs before args is defined, it's a no-op\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5538f3",
   "metadata": {},
   "source": [
    "## Render\n",
    "\n",
    "NeRF rendering utilities\n",
    "\n",
    "This part contains helper functions to render volumes using Neural Radiance Fields (NeRF).\n",
    "If you're new to NeRF, here's the high-level idea you'll see reflected in the code:\n",
    "\n",
    "- A NeRF model takes a 3D point (and often a viewing direction) and predicts color (RGB)\n",
    "  and density (sigma) at that point.\n",
    "- To render an image, we cast a ray through each pixel, sample many points along the ray,\n",
    "  evaluate the network at those points, and composite the colors using volume rendering.\n",
    "- We optionally do this in two passes: a coarse pass to find where the scene is, then a\n",
    "  fine pass that samples more densely in the important regions (importance sampling).\n",
    "\n",
    "The functions below help with:\n",
    "- Splitting big tensors/ray sets into smaller chunks to avoid out-of-memory issues.\n",
    "- Converting raw network outputs into rendered RGB/depth/opacity via volume rendering.\n",
    "- Orchestrating the full per-ray rendering with optional hierarchical sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d11a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following function wraps a function fn so it processes a large input tensor in smaller chunks\n",
    "to reduce peak memory usage, then stitches the result together.\n",
    "\n",
    "This splits inputs along the first dimension into slices of size chunk and applies fn to each slice.\n",
    "Then it concatenates the results back together along the first dimension.\n",
    "\n",
    "This reduces gpu and cpu spikes when fn is heavy (i.e neural network forward pass) and preserves\n",
    "autograd, as gradients flow through torch.cat and slicing.\n",
    "\"\"\"\n",
    "def batchify(fn, chunk):\n",
    "    \"\"\"Wrap a function so it runs on smaller input chunks to reduce peak memory.\n",
    "\n",
    "    This is useful for heavy functions like neural network forward passes. Instead of\n",
    "    evaluating the entire input tensor in one go, we split it along the first dimension\n",
    "    into slices of size ``chunk`` and then concatenate the results.\n",
    "\n",
    "    Args:\n",
    "        fn (Callable[[Tensor], Tensor]): The function to run on chunks.\n",
    "        chunk (Optional[int]): Number of rows to process per call. If ``None``,\n",
    "            no chunking is performed.\n",
    "\n",
    "    Returns:\n",
    "        Callable[[Tensor], Tensor]: A wrapper that applies ``fn`` on input chunks and\n",
    "        stitches the outputs along the first dimension.\n",
    "    \"\"\"\n",
    "    if chunk is None:\n",
    "        return fn\n",
    "    def ret(inputs):\n",
    "        return torch.cat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c35c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw2outputs(raw, z_vals, rays_d, raw_noise_std=0, white_bkgd=False, pytest=False):\n",
    "    \"\"\"\n",
    "    Convert raw network predictions along rays into rendered outputs using\n",
    "    volumetric rendering (accumulation over samples).\n",
    "\n",
    "    High-level intuition (NeRF volume rendering):\n",
    "    - The network predicts, per sampled point along a ray, an RGB value and a density\n",
    "      (often called sigma). Density indicates how much light is absorbed/emitted there.\n",
    "    - We turn densities into per-sample opacities (alpha) based on the distance between\n",
    "      adjacent samples along the ray.\n",
    "    - We compute transmittance (how much light makes it to a sample without being blocked)\n",
    "      via a cumulative product, then form per-sample weights = transmittance * alpha.\n",
    "    - We composite colors, depths, and other quantities by weighted sums over samples.\n",
    "\n",
    "    Args:\n",
    "        raw (torch.Tensor): [N_rays, N_samples, 4] raw predictions per sample. The first\n",
    "            3 channels are RGB logits (before sigmoid), and the last channel is density (sigma).\n",
    "        z_vals (torch.Tensor): [N_rays, N_samples] sample depths or t-values along each ray.\n",
    "        rays_d (torch.Tensor): [N_rays, 3] direction vectors for each ray. Used to scale\n",
    "            step sizes from parametric units to metric distances.\n",
    "        raw_noise_std (float): Stddev of Gaussian noise added to sigma during training for\n",
    "            regularization. Set to 0.0 at eval time.\n",
    "        white_bkgd (bool): If True, composite the result over a white background (useful\n",
    "            for synthetic datasets rendered on white).\n",
    "        pytest (bool): If True, use deterministic numpy noise for reproducible tests.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - rgb_map (torch.Tensor): [N_rays, 3] rendered RGB color per ray.\n",
    "            - disp_map (torch.Tensor): [N_rays] disparity (inverse depth) per ray.\n",
    "            - acc_map (torch.Tensor): [N_rays] accumulated opacity per ray (sum of weights).\n",
    "            - weights (torch.Tensor): [N_rays, N_samples] per-sample contribution weights.\n",
    "            - depth_map (torch.Tensor): [N_rays] expected depth per ray.\n",
    "    \"\"\"\n",
    "    # Map density (sigma) and step size (distance between samples) to opacity (alpha):\n",
    "    #   alpha = 1 - exp(-relu(sigma) * delta)\n",
    "    # relu ensures sigma is non-negative, as negative density is not physical.\n",
    "    raw2alpha = lambda raw_sigma, dists, act_fn=F.relu: 1.0 - torch.exp(-act_fn(raw_sigma) * dists)\n",
    "\n",
    "    # Compute distances between adjacent samples along each ray in z (or t) space.\n",
    "    # Shape after diff: [N_rays, N_samples-1]\n",
    "    dists = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "\n",
    "    # For the last sample on each ray, append a very large distance so that its\n",
    "    # contribution is properly modeled as the ray exiting the volume.\n",
    "    # Resulting shape: [N_rays, N_samples]\n",
    "    dists = torch.cat([dists, torch.tensor([1e10], device=z_vals.device, dtype=z_vals.dtype).expand(dists[..., :1].shape)], dim=-1)\n",
    "\n",
    "    # Convert parametric distances to metric distances by multiplying by the ray length.\n",
    "    # This accounts for non-unit ray directions. rays_d[..., None, :] has shape [N_rays, 1, 3]\n",
    "    # and we take its L2 norm to scale each sample distance.\n",
    "    dists = dists * torch.norm(rays_d[..., None, :], dim=-1)\n",
    "\n",
    "    # Convert raw RGB logits to [0,1] colors per sample.\n",
    "    rgb = torch.sigmoid(raw[..., :3])  # [N_rays, N_samples, 3]\n",
    "\n",
    "    # Optional noise added to densities during training for regularization.\n",
    "    # Ensure raw_noise_std is a float (configs may pass strings).\n",
    "    try:\n",
    "        noise_std = float(raw_noise_std)\n",
    "    except (TypeError, ValueError):\n",
    "        noise_std = 0.0\n",
    "\n",
    "    noise = 0.0\n",
    "    if noise_std > 0.0:\n",
    "        noise = torch.randn(raw[..., 3].shape, device=raw.device, dtype=raw.dtype) * noise_std\n",
    "\n",
    "        # Deterministic noise path for unit tests.\n",
    "        if pytest:\n",
    "            np.random.seed(0)\n",
    "            noise_np = np.random.rand(*list(raw[..., 3].shape)) * noise_std\n",
    "            noise = torch.tensor(noise_np, device=raw.device, dtype=raw.dtype)\n",
    "\n",
    "    # Opacity per sample from density and distance.\n",
    "    alpha = raw2alpha(raw[..., 3] + noise, dists)  # [N_rays, N_samples]\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1), device=alpha.device, dtype=alpha.dtype), 1.-alpha + 1e-10], -1), -1)[:, :-1]\n",
    "\n",
    "    # Rendered color is the weighted sum of per-sample colors along the ray.\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, dim=-2)  # [N_rays, 3]\n",
    "\n",
    "    # Expected depth is the weighted sum of sample depths.\n",
    "    depth_map = torch.sum(weights * z_vals, dim=-1)\n",
    "\n",
    "    # Disparity is inverse depth. We divide expected depth by total weight (visibility)\n",
    "    # and guard with epsilon to avoid divide-by-zero when the ray hits nothing.\n",
    "    denom = torch.max(1e-10 * torch.ones_like(depth_map), torch.sum(weights, dim=-1))\n",
    "    disp_map = 1.0 / torch.clamp(depth_map / denom, min=1e-10)\n",
    "\n",
    "    # Accumulated opacity along the ray (how much of the ray got \"stopped\").\n",
    "    acc_map = torch.sum(weights, dim=-1)\n",
    "\n",
    "    # If the scene assumes a white background, composite the missing transmittance as white.\n",
    "    if white_bkgd:\n",
    "        rgb_map = rgb_map + (1.0 - acc_map[..., None])\n",
    "\n",
    "    return rgb_map, disp_map, acc_map, weights, depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6208cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(ray_batch,\n",
    "                network_fn,\n",
    "                network_query_fn,\n",
    "                N_samples,\n",
    "                retraw=False,\n",
    "                lindisp=False,\n",
    "                perturb=0.,\n",
    "                N_importance=0,\n",
    "                network_fine=None,\n",
    "                white_bkgd=False,\n",
    "                raw_noise_std=0.,\n",
    "                verbose=False,\n",
    "                pytest=False):\n",
    "    \"\"\"Render a bundle of rays using NeRF-style volume rendering.\n",
    "\n",
    "    High-level steps for each ray:\n",
    "    1) Sample N points between near and far along the ray (evenly in depth or inverse depth).\n",
    "    2) Query the network at those 3D points (and optionally view directions) to get raw RGB+sigma.\n",
    "    3) Convert raw predictions to colors via volume rendering (accumulate with alphas/weights).\n",
    "    4) If enabled, run hierarchical (importance) sampling: take a second set of samples drawn\n",
    "       from a PDF defined by the coarse weights, re-evaluate the network (fine), and re-render.\n",
    "\n",
    "    Args:\n",
    "        ray_batch (torch.Tensor): [num_rays, Cray]. Per-ray data packed together. The first\n",
    "            3 entries are ray origins, next 3 are ray directions, next 2 are near/far bounds,\n",
    "            and the last 3 (if present) are unit view directions for view-dependent effects.\n",
    "        network_fn (Callable): The coarse NeRF MLP. Given points (and viewdirs), predicts\n",
    "            raw RGB (logits) and density (sigma).\n",
    "        network_query_fn (Callable): A helper that formats inputs and calls the network.\n",
    "        N_samples (int): Number of stratified samples for the coarse pass.\n",
    "        retraw (bool): If True, also return the raw outputs from the last pass.\n",
    "        lindisp (bool): If True, sample uniformly in inverse depth (disparity) instead of depth.\n",
    "            This concentrates samples near the camera, helpful for scenes with large depth ranges.\n",
    "        perturb (float): If > 0, enable stratified sampling noise during training for anti-aliasing.\n",
    "        N_importance (int): Extra samples for the fine pass (hierarchical sampling). 0 disables it.\n",
    "        network_fine (Optional[Callable]): A separate fine MLP. If None, reuse ``network_fn``.\n",
    "        white_bkgd (bool): If True, composite the result over a white background.\n",
    "        raw_noise_std (float): Stddev of Gaussian noise added to density during training.\n",
    "        verbose (bool): If True, print additional debug information.\n",
    "        pytest (bool): If True, make randomness deterministic for unit tests.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: Always includes:\n",
    "            - ``rgb_map`` [num_rays, 3]: Rendered color from the last pass (fine if enabled).\n",
    "            - ``disp_map`` [num_rays]: Disparity (1/depth) from the last pass.\n",
    "            - ``acc_map`` [num_rays]: Accumulated opacity from the last pass.\n",
    "        Optionally includes:\n",
    "            - ``raw`` [num_rays, num_samples, 4]: Raw outputs of the last pass if ``retraw``.\n",
    "            - ``rgb0``, ``disp0``, ``acc0``: Coarse pass results when ``N_importance > 0``.\n",
    "            - ``z_std`` [num_rays]: Std. dev. of fine samples (measures sampling concentration).\n",
    "    \"\"\"\n",
    "    N_rays = ray_batch.shape[0]\n",
    "   # Unpack packed ray data: origins, directions, near/far bounds, and optional viewdirs.\n",
    "    rays_o, rays_d = ray_batch[:,0:3], ray_batch[:,3:6] # [N_rays, 3] each\n",
    "    viewdirs = ray_batch[:,-3:] if ray_batch.shape[-1] > 8 else None\n",
    "    bounds = torch.reshape(ray_batch[...,6:8], [-1,1,2])\n",
    "    near, far = bounds[...,0], bounds[...,1] # [-1,1]\n",
    "\n",
    "    # Step 1: Choose parametric sample positions t in [0, 1] and map to depths z in [near, far].\n",
    "    t_vals = torch.linspace(0., 1., steps=N_samples, device=ray_batch.device)\n",
    "    if not lindisp:\n",
    "        # Uniform samples in depth\n",
    "        z_vals = near * (1.-t_vals) + far * (t_vals)\n",
    "    else:\n",
    "        # Uniform samples in inverse depth (places more samples closer to the camera)\n",
    "        z_vals = 1./(1./near * (1.-t_vals) + 1./far * (t_vals))\n",
    "\n",
    "    z_vals = z_vals.expand([N_rays, N_samples])\n",
    "\n",
    "    if perturb > 0.:\n",
    "        # During training, jitter samples within each interval for stratified sampling.\n",
    "        # This reduces aliasing and improves robustness.\n",
    "        # Get intervals between samples\n",
    "        mids = .5 * (z_vals[...,1:] + z_vals[...,:-1])\n",
    "        upper = torch.cat([mids, z_vals[...,-1:]], -1)\n",
    "        lower = torch.cat([z_vals[...,:1], mids], -1)\n",
    "        # Draw stratified samples inside those intervals\n",
    "        t_rand = torch.rand(z_vals.shape, device=z_vals.device)\n",
    "\n",
    "        # Pytest, overwrite u with numpy's fixed random numbers\n",
    "        if pytest:\n",
    "            np.random.seed(0)\n",
    "            t_rand = np.random.rand(*list(z_vals.shape))\n",
    "            t_rand = torch.tensor(t_rand, device=z_vals.device, dtype=z_vals.dtype)\n",
    "\n",
    "        z_vals = lower + (upper - lower) * t_rand\n",
    "\n",
    "    # Compute 3D sample locations along each ray: o + t*d for each sampled depth t (z_vals).\n",
    "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None] # [N_rays, N_samples, 3]\n",
    "\n",
    "    # raw = run_network(pts)\n",
    "    # Query the (coarse) network at all sample points. ``viewdirs`` enables view-dependent effects.\n",
    "    raw = network_query_fn(pts, viewdirs, network_fn)\n",
    "    rgb_map, disp_map, acc_map, weights, depth_map = raw2outputs(raw, z_vals, rays_d, raw_noise_std, white_bkgd, pytest=pytest)\n",
    "\n",
    "    if N_importance > 0:\n",
    "\n",
    "        rgb_map_0, disp_map_0, acc_map_0 = rgb_map, disp_map, acc_map\n",
    "\n",
    "        # Hierarchical sampling (importance sampling):\n",
    "        # Build a PDF from coarse weights and draw additional samples where the scene is likely.\n",
    "        z_vals_mid = .5 * (z_vals[...,1:] + z_vals[...,:-1])\n",
    "        # Exclude the first and last weights to avoid boundary artifacts when forming the PDF.\n",
    "        z_samples = sample_pdf(z_vals_mid, weights[...,1:-1], N_importance, det=(perturb==0.), pytest=pytest)\n",
    "        # Detach so gradients do not flow through the sampling operation.\n",
    "        z_samples = z_samples.detach()\n",
    "\n",
    "        # Merge coarse and fine samples, then sort along the ray.\n",
    "        z_vals, _ = torch.sort(torch.cat([z_vals, z_samples], -1), -1)\n",
    "        pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None] # [N_rays, N_samples + N_importance, 3]\n",
    "\n",
    "        # Use dedicated fine network if provided, else reuse the coarse network.\n",
    "        run_fn = network_fn if network_fine is None else network_fine\n",
    "        # raw = run_network(pts, fn=run_fn)\n",
    "        raw = network_query_fn(pts, viewdirs, run_fn)\n",
    "\n",
    "        rgb_map, disp_map, acc_map, weights, depth_map = raw2outputs(raw, z_vals, rays_d, raw_noise_std, white_bkgd, pytest=pytest)\n",
    "\n",
    "    ret = {'rgb_map' : rgb_map, 'disp_map' : disp_map, 'acc_map' : acc_map}\n",
    "    if retraw:\n",
    "        ret['raw'] = raw\n",
    "    if N_importance > 0:\n",
    "        # Include coarse pass results for potential losses or visualization.\n",
    "        ret['rgb0'] = rgb_map_0\n",
    "        ret['disp0'] = disp_map_0\n",
    "        ret['acc0'] = acc_map_0\n",
    "        # Standard deviation of fine samples: indicates how concentrated sampling is per ray.\n",
    "        ret['z_std'] = torch.std(z_samples, dim=-1, unbiased=False)  # [N_rays]\n",
    "\n",
    "    for k in ret:\n",
    "        if (torch.isnan(ret[k]).any() or torch.isinf(ret[k]).any()) and DEBUG:\n",
    "            print(f\"! [Numerical Error] {k} contains nan or inf.\")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30896c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Render a large set of rays by splitting them into manageable minibatches to avoid\n",
    "out-of-memory (OOM) issues, then stitch the per-batch results back together.\n",
    "\n",
    "High-level intuition:\n",
    "- Rendering involves evaluating many rays (often millions). Each ray requires sampling\n",
    "  points, running an MLP, and compositing colors/densities, which can be memory-heavy.\n",
    "- Instead of rendering all rays at once, we process them in chunks (minibatches), which\n",
    "  keeps peak memory usage bounded.\n",
    "- We collect and concatenate the results for each output quantity (e.g., rgb, depth, acc).\n",
    "\"\"\"\n",
    "\n",
    "def batchify_rays(rays_flat, chunk=1024*32, **kwargs):\n",
    "    \"\"\"\n",
    "    Render rays in smaller minibatches to avoid OOM.\n",
    "\n",
    "    Args:\n",
    "        rays_flat (torch.Tensor): Rays flattened along the batch dimension, shape [N, Cray].\n",
    "            Each row encodes a single ray's data (e.g., origin, direction, near/far, etc.).\n",
    "        chunk (int): Number of rays to render per minibatch.\n",
    "        **kwargs: Additional keyword arguments forwarded to `render_rays` (e.g., models,\n",
    "            sampling counts, noise parameters).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: A dictionary where each key corresponds to a rendered\n",
    "        quantity (e.g., 'rgb_map', 'disp_map', 'acc_map', etc.), and each tensor has\n",
    "        shape [N, ...], formed by concatenating per-chunk outputs along the first dimension.\n",
    "    \"\"\"\n",
    "    # Accumulate lists of per-chunk outputs in a dictionary keyed by output name.\n",
    "    all_ret = {}\n",
    "\n",
    "    # Iterate over rays in chunks: [0:chunk], [chunk:2*chunk], ...\n",
    "    for i in range(0, rays_flat.shape[0], chunk):\n",
    "        # Render a minibatch of rays using the provided rendering function and settings.\n",
    "        ret = render_rays(rays_flat[i:i+chunk], **kwargs)\n",
    "\n",
    "        # For each output field produced by the renderer, append the minibatch result\n",
    "        # to a growing list so we can concatenate later.\n",
    "        for k in ret:\n",
    "            if k not in all_ret:\n",
    "                all_ret[k] = []\n",
    "            all_ret[k].append(ret[k])\n",
    "\n",
    "    # Concatenate lists of chunk results into full [N, ...] tensors for each field.\n",
    "    all_ret = {k: torch.cat(all_ret[k], dim=0) for k in all_ret}\n",
    "\n",
    "    return all_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e728037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(H, W, K, chunk=1024*32, rays=None, c2w=None, ndc=True,\n",
    "                  near=0., far=1.,\n",
    "                  use_viewdirs=False, c2w_staticcam=None,\n",
    "                  **kwargs):\n",
    "    \"\"\"Render a full image or a provided set of rays using NeRF.\n",
    "\n",
    "    There are two common ways to call this function:\n",
    "    - Full image: pass a camera-to-world matrix ``c2w`` and camera intrinsics ``K``.\n",
    "      The function will generate one ray per pixel and render all of them.\n",
    "    - Custom rays: pass ``rays=(rays_o, rays_d)`` to render only those rays.\n",
    "\n",
    "    Args:\n",
    "        H (int): Image height in pixels.\n",
    "        W (int): Image width in pixels.\n",
    "        K (torch.Tensor or np.ndarray): 3x3 camera intrinsics matrix. We use ``K[0,0]``\n",
    "            (focal length in pixels) when converting to NDC for forward-facing scenes.\n",
    "        chunk (int): Max number of rays to process per minibatch to control memory usage.\n",
    "        rays (tuple[Tensor, Tensor], optional): Tuple ``(rays_o, rays_d)`` with shapes\n",
    "            [..., 3] each, giving ray origins and directions. If provided, ``c2w`` is ignored.\n",
    "        c2w (torch.Tensor or np.ndarray, optional): [3,4] camera-to-world matrix. If provided,\n",
    "            rays for the full image are generated via ``get_rays``.\n",
    "        ndc (bool): If True, convert rays to normalized device coordinates (recommended for\n",
    "            forward-facing scenes as in the original NeRF paper).\n",
    "        near (float): Near plane distance used to initialize per-ray near bounds.\n",
    "        far (float): Far plane distance used to initialize per-ray far bounds.\n",
    "        use_viewdirs (bool): If True, pass unit viewing directions to the network to enable\n",
    "            view-dependent appearance (specularities).\n",
    "        c2w_staticcam (torch.Tensor or np.ndarray, optional): If provided with ``use_viewdirs``\n",
    "            enabled, generate rays from ``c2w_staticcam`` but keep view directions from ``c2w``.\n",
    "            This is useful to visualize how view-dependent effects change with direction.\n",
    "        **kwargs: Forwarded to ``render_rays`` (e.g., networks, sample counts, noise settings).\n",
    "\n",
    "    Returns:\n",
    "        list: ``[rgb_map, disp_map, acc_map, extras]``\n",
    "            - rgb_map: [H, W, 3] rendered colors\n",
    "            - disp_map: [H, W] disparity (1/depth)\n",
    "            - acc_map: [H, W] accumulated opacity\n",
    "            - extras: dict with any additional outputs from ``render_rays``\n",
    "    \"\"\"\n",
    "    # Infer rendering device from the model to keep all tensors consistent\n",
    "    model_device = next(kwargs['network_fn'].parameters()).device\n",
    "\n",
    "    if c2w is not None:\n",
    "        # Special case: render a full image by generating one ray per pixel.\n",
    "        rays_o, rays_d = get_rays(H, W, K, c2w)\n",
    "    else:\n",
    "        # Use the provided custom ray batch.\n",
    "        rays_o, rays_d = rays\n",
    "\n",
    "    if use_viewdirs:\n",
    "        # Provide normalized ray directions to the network for view-dependent effects.\n",
    "        viewdirs = rays_d\n",
    "        if c2w_staticcam is not None:\n",
    "            # Visualize only the effect of changing view direction while keeping camera fixed.\n",
    "            rays_o, rays_d = get_rays(H, W, K, c2w_staticcam)\n",
    "        viewdirs = viewdirs / torch.norm(viewdirs, dim=-1, keepdim=True)\n",
    "        viewdirs = torch.reshape(viewdirs, [-1,3]).float().to(model_device)\n",
    "\n",
    "    sh = rays_d.shape # [..., 3]\n",
    "    if ndc:\n",
    "        # Convert to NDC (assumes a pinhole camera model), commonly used for LLFF/forward-facing scenes.\n",
    "        rays_o, rays_d = ndc_rays(H, W, K[0][0], 1., rays_o, rays_d)\n",
    "\n",
    "    # Create ray batch\n",
    "    rays_o = torch.reshape(rays_o, [-1,3]).float().to(model_device)\n",
    "    rays_d = torch.reshape(rays_d, [-1,3]).float().to(model_device)\n",
    "\n",
    "    # Initialize per-ray near/far bounds and pack rays into a single tensor expected by render_rays.\n",
    "    near, far = near * torch.ones_like(rays_d[...,:1]), far * torch.ones_like(rays_d[...,:1])\n",
    "    rays = torch.cat([rays_o, rays_d, near, far], -1)\n",
    "    if use_viewdirs:\n",
    "        rays = torch.cat([rays, viewdirs], -1)\n",
    "\n",
    "    # Render all rays in memory-friendly chunks, then reshape results back to image grids.\n",
    "    all_ret = batchify_rays(rays, chunk, **kwargs)\n",
    "    for k in all_ret:\n",
    "        k_sh = list(sh[:-1]) + list(all_ret[k].shape[1:])\n",
    "        all_ret[k] = torch.reshape(all_ret[k], k_sh)\n",
    "\n",
    "    k_extract = ['rgb_map', 'disp_map', 'acc_map']\n",
    "    ret_list = [all_ret[k] for k in k_extract]\n",
    "    ret_dict = {k : all_ret[k] for k in all_ret if k not in k_extract}\n",
    "    return ret_list + [ret_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f0ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_path(render_poses, hwf, K, chunk, render_kwargs, gt_imgs=None, savedir=None, render_factor=0, \n",
    "                calculate_metrics=False, metrics_include_lpips=True, metrics_device='cuda'):\n",
    "    \"\"\"Render a sequence of camera poses to produce a video or trajectory.\n",
    "\n",
    "    This convenience function loops over a list/array of camera-to-world matrices and calls\n",
    "    ``render`` for each pose. Optionally writes frames to ``savedir`` and/or renders at a\n",
    "    lower resolution for speed.\n",
    "\n",
    "    Args:\n",
    "        render_poses (Iterable[Tensor or np.ndarray]): Sequence of [3,4] camera-to-world matrices.\n",
    "        hwf (tuple): ``(H, W, focal)`` from dataset metadata. Only ``H`` and ``W`` are used here.\n",
    "        K (Tensor or np.ndarray): 3x3 intrinsics matrix passed through to ``render``.\n",
    "        chunk (int): Chunk size forwarded to ``render``.\n",
    "        render_kwargs (dict): Keyword args forwarded to ``render`` (e.g., networks and settings).\n",
    "        gt_imgs (optional): Ground-truth images; if provided, you can compute metrics.\n",
    "        savedir (str, optional): If provided, write each rendered RGB frame as a PNG to this folder.\n",
    "        render_factor (int): If > 0, downsample H and W by this factor to render faster.\n",
    "        calculate_metrics (bool): If True and gt_imgs is provided, calculate image quality metrics.\n",
    "        metrics_include_lpips (bool): Whether to include LPIPS in metrics calculation.\n",
    "        metrics_device (str): Device to use for LPIPS calculation.\n",
    "\n",
    "    Returns:\n",
    "        If calculate_metrics=False: Tuple[np.ndarray, np.ndarray]: ``(rgbs, disps)``\n",
    "        If calculate_metrics=True: Tuple[np.ndarray, np.ndarray, dict]: ``(rgbs, disps, metrics)``\n",
    "        where metrics contains averaged PSNR, SSIM, and optionally LPIPS values.\n",
    "    \"\"\"\n",
    "\n",
    "    H, W, focal = hwf\n",
    "\n",
    "    if render_factor!=0:\n",
    "        # Render downsampled for speed by reducing both resolution and focal length proportionally.\n",
    "        H = H//render_factor\n",
    "        W = W//render_factor\n",
    "        focal = focal/render_factor\n",
    "\n",
    "    rgbs = []\n",
    "    disps = []\n",
    "    \n",
    "    # Initialize metrics collection if requested\n",
    "    if calculate_metrics and gt_imgs is not None:\n",
    "        from nerf_helpers import calculate_metrics as calc_metrics\n",
    "        all_metrics = {'psnr': [], 'ssim': [], 'mse': []}\n",
    "        if metrics_include_lpips:\n",
    "            all_metrics['lpips'] = []\n",
    "\n",
    "    t = time.time()\n",
    "    for i, c2w in enumerate(tqdm(render_poses)):\n",
    "        # Simple timing print to monitor rendering speed\n",
    "        print(i, time.time() - t)\n",
    "        t = time.time()\n",
    "\n",
    "        # Render the current pose; we discard the accumulated opacity and extras here\n",
    "        rgb, disp, acc, _ = render(H, W, K, chunk=chunk, c2w=c2w[:3,:4], **render_kwargs)\n",
    "        rgbs.append(rgb.cpu().numpy())\n",
    "        disps.append(disp.cpu().numpy())\n",
    "        if i==0:\n",
    "            print(rgb.shape, disp.shape)\n",
    "\n",
    "        # Calculate metrics vs. ground truth if requested\n",
    "        if calculate_metrics and gt_imgs is not None and render_factor==0 and i < len(gt_imgs):\n",
    "            gt_img = gt_imgs[i]\n",
    "            rendered_img = rgb.cpu().numpy()\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            metrics = calc_metrics(rendered_img, gt_img, \n",
    "                                 include_lpips=metrics_include_lpips, \n",
    "                                 device=metrics_device)\n",
    "            \n",
    "            # Store metrics\n",
    "            for key in all_metrics:\n",
    "                if key in metrics and metrics[key] is not None:\n",
    "                    all_metrics[key].append(metrics[key])\n",
    "            \n",
    "            # Print metrics for this frame\n",
    "            print(f\"Frame {i} - PSNR: {metrics.get('psnr', 'N/A'):.2f}, \"\n",
    "                  f\"SSIM: {metrics.get('ssim', 'N/A'):.4f}\", end=\"\")\n",
    "            if metrics_include_lpips and 'lpips' in metrics:\n",
    "                print(f\", LPIPS: {metrics.get('lpips', 'N/A'):.4f}\")\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "        # Optionally write the frame to disk as an 8-bit PNG.\n",
    "        if savedir is not None:\n",
    "            rgb8 = to8b(rgbs[-1])\n",
    "            filename = os.path.join(savedir, '{:03d}.png'.format(i))\n",
    "            imageio.imwrite(filename, rgb8)\n",
    "\n",
    "    # Stack lists into contiguous arrays with a time dimension.\n",
    "    rgbs = np.stack(rgbs, 0)\n",
    "    disps = np.stack(disps, 0)\n",
    "\n",
    "    # Calculate average metrics if requested\n",
    "    if calculate_metrics and gt_imgs is not None:\n",
    "        avg_metrics = {}\n",
    "        for key, values in all_metrics.items():\n",
    "            if values:  # Only average if we have values\n",
    "                avg_metrics[f'avg_{key}'] = np.mean(values)\n",
    "                avg_metrics[f'std_{key}'] = np.std(values)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n=== METRICS SUMMARY ===\")\n",
    "        for key in ['psnr', 'ssim', 'lpips']:\n",
    "            if f'avg_{key}' in avg_metrics:\n",
    "                print(f\"Average {key.upper()}: {avg_metrics[f'avg_{key}']:.4f} ± {avg_metrics[f'std_{key}']:.4f}\")\n",
    "        print(\"=======================\")\n",
    "        \n",
    "        return rgbs, disps, avg_metrics\n",
    "\n",
    "    return rgbs, disps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0111889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare 3D sample points for a NeRF-style network by applying positional encodings,\n",
    "run the network on these encodings in memory-safe chunks, and then reshape the results\n",
    "back to the original sampling layout.\n",
    "\n",
    "High-level intuition:\n",
    "- We often sample many 3D points (xyz) per ray and, optionally, use a per-ray viewing\n",
    "  direction. Raw coordinates are hard for small MLPs to learn high-frequency detail,\n",
    "  so we first apply a positional encoding that maps them to a higher-dimensional space.\n",
    "- We flatten everything to a big batch so the network can process all samples uniformly.\n",
    "- To avoid running out of memory, we split this big batch into chunks and process them\n",
    "  sequentially, then stitch the outputs back together and restore the original shape.\n",
    "\"\"\"\n",
    "\n",
    "def run_network(inputs, viewdirs, fn, embed_fn, embeddirs_fn, netchunk=1024*64):\n",
    "    \"\"\"\n",
    "    Prepare inputs for a NeRF-style MLP and apply the network in chunks.\n",
    "\n",
    "    Conceptual overview:\n",
    "    - Positions (xyz) and, optionally, viewing directions are first positional-encoded\n",
    "      (a deterministic mapping to a higher-dimensional space using sin/cos at multiple\n",
    "      frequencies). This helps the MLP represent fine details and sharp changes.\n",
    "    - We flatten leading dimensions so all samples are processed as a single batch.\n",
    "    - To keep memory usage in check, we process this batch in chunks (netchunk).\n",
    "    - Finally, we reshape outputs to match the original sampling layout.\n",
    "\n",
    "    Args:\n",
    "        inputs (torch.Tensor): Sample positions with shape [..., Cpos], typically Cpos = 3.\n",
    "            Example: [N_rays, N_samples, 3]. The leading dimensions can be any shape.\n",
    "        viewdirs (Optional[torch.Tensor]): Per-ray viewing directions with shape\n",
    "            [N_rays, Cdir] (typically Cdir = 3), or None if not using view-dependent effects.\n",
    "            When provided, each ray direction is broadcast to all samples along that ray.\n",
    "        fn (Callable[[torch.Tensor], torch.Tensor]): Neural network (e.g., NeRF MLP) that\n",
    "            consumes encoded features and returns outputs per sample.\n",
    "        embed_fn (Callable[[torch.Tensor], torch.Tensor]): Positional encoder for positions;\n",
    "            maps [*, Cpos] -> [*, Cpos_enc].\n",
    "        embeddirs_fn (Optional[Callable[[torch.Tensor], torch.Tensor]]): Positional encoder\n",
    "            for directions; maps [*, Cdir] -> [*, Cdir_enc]. Only used if viewdirs is not None.\n",
    "        netchunk (int): Maximum number of samples to process per chunk to limit peak memory.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Network outputs with shape [..., Cout], where the leading dimensions\n",
    "        match those of `inputs` (excluding its last channel), and Cout is determined by `fn`.\n",
    "    \"\"\"\n",
    "    # Flatten all leading dimensions so we have a simple [N, Cpos] batch of positions.\n",
    "    # N is the total number of samples across rays and per-ray samples.\n",
    "    inputs_flat = torch.reshape(inputs, [-1, inputs.shape[-1]])\n",
    "\n",
    "    # Positional-encode the flattened positions (e.g., apply sin/cos at multiple frequencies).\n",
    "    # This expands each 3D input into a richer, higher-dimensional representation\n",
    "    # that makes it easier for the MLP to model fine spatial detail.\n",
    "    embedded = embed_fn(inputs_flat)\n",
    "\n",
    "    # If using view-dependent appearance (e.g., specular highlights that vary with direction),\n",
    "    # we also encode per-ray viewing directions and concatenate them with position encodings.\n",
    "    if viewdirs is not None:\n",
    "        # Insert a length-1 axis, then broadcast each ray direction across all samples on that ray\n",
    "        # so that every sample point along a ray shares the same view direction.\n",
    "        input_dirs = viewdirs[:, None].expand(inputs.shape)\n",
    "\n",
    "        # Flatten directions to align with the flattened positions: [N, Cdir].\n",
    "        input_dirs_flat = torch.reshape(input_dirs, [-1, input_dirs.shape[-1]])\n",
    "\n",
    "        # Positional-encode viewing directions in the same spirit as positions.\n",
    "        embedded_dirs = embeddirs_fn(input_dirs_flat)\n",
    "\n",
    "        # Concatenate encoded positions and encoded directions along the feature/channel axis.\n",
    "        embedded = torch.cat([embedded, embedded_dirs], -1)\n",
    "\n",
    "    # Apply the network to the encoded features in memory-safe chunks along the batch dimension.\n",
    "    # This prevents out-of-memory errors when the total number of samples is very large.\n",
    "    # Ensure inputs are on the same device as the model parameters.\n",
    "    model_device = next(fn.parameters()).device\n",
    "    embedded = embedded.to(model_device)\n",
    "    outputs_flat = batchify(fn, netchunk)(embedded)\n",
    "\n",
    "    # Restore the original leading shape (e.g., [N_rays, N_samples]) and append the output channels.\n",
    "    outputs = torch.reshape(outputs_flat, list(inputs.shape[:-1]) + [outputs_flat.shape[-1]])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf79950",
   "metadata": {},
   "source": [
    "## Instantiate NeRF\n",
    "This section creates a function to instantiate NeRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab3b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf import NeRF\n",
    "\n",
    "def create_nerf(args):\n",
    "    \"\"\"Instantiate NeRF's MLP model.\n",
    "    \"\"\"\n",
    "    embed_fn, input_ch = get_embedder(args.multires, args.i_embed)\n",
    "\n",
    "    input_ch_views = 0\n",
    "    embeddirs_fn = None\n",
    "    if args.use_viewdirs:\n",
    "        embeddirs_fn, input_ch_views = get_embedder(args.multires_views, args.i_embed)\n",
    "    output_ch = 5 if args.N_importance > 0 else 4\n",
    "    skips = [4]\n",
    "    model = NeRF(D=args.netdepth, W=args.netwidth,\n",
    "                 input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "                 input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)\n",
    "    grad_vars = list(model.parameters())\n",
    "\n",
    "    model_fine = None\n",
    "    if args.N_importance > 0:\n",
    "        model_fine = NeRF(D=args.netdepth_fine, W=args.netwidth_fine,\n",
    "                          input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "                          input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)\n",
    "        grad_vars += list(model_fine.parameters())\n",
    "\n",
    "    network_query_fn = lambda inputs, viewdirs, network_fn : run_network(inputs, viewdirs, network_fn,\n",
    "                                                                embed_fn=embed_fn,\n",
    "                                                                embeddirs_fn=embeddirs_fn,\n",
    "                                                                netchunk=args.netchunk)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.Adam(params=grad_vars, lr=args.lrate, betas=(0.9, 0.999))\n",
    "\n",
    "    start = 0\n",
    "    basedir = args.basedir\n",
    "    expname = args.expname\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    # Load checkpoints\n",
    "    # Make checkpt dirs\n",
    "    checkpoint_dir = os.path.join(basedir, expname, \"checkpoints\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    if args.ft_path is not None and args.ft_path!='None':\n",
    "        ckpts = [args.ft_path]\n",
    "    else:\n",
    "        ckpts = [os.path.join(basedir, expname, \"checkpoints\", f) for f in sorted(os.listdir(os.path.join(basedir, expname, \"checkpoints\"))) if 'tar' in f]\n",
    "\n",
    "    print('Found ckpts', ckpts)\n",
    "    if len(ckpts) > 0 and not args.no_reload:\n",
    "        ckpt_path = ckpts[-1]\n",
    "        print('Reloading from', ckpt_path)\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "\n",
    "        start = ckpt['global_step']\n",
    "        optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "\n",
    "        # Load model\n",
    "        model.load_state_dict(ckpt['network_fn_state_dict'])\n",
    "        if model_fine is not None:\n",
    "            model_fine.load_state_dict(ckpt['network_fine_state_dict'])\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    render_kwargs_train = {\n",
    "        'network_query_fn' : network_query_fn,\n",
    "        'perturb' : args.perturb,\n",
    "        'N_importance' : args.N_importance,\n",
    "        'network_fine' : model_fine,\n",
    "        'N_samples' : args.N_samples,\n",
    "        'network_fn' : model,\n",
    "        'use_viewdirs' : args.use_viewdirs,\n",
    "        'white_bkgd' : args.white_bkgd,\n",
    "        'raw_noise_std' : args.raw_noise_std,\n",
    "    }\n",
    "\n",
    "    # NDC only good for LLFF-style forward facing data\n",
    "    if args.dataset_type != 'llff' or args.no_ndc:\n",
    "        print('Not ndc!')\n",
    "        render_kwargs_train['ndc'] = False\n",
    "        render_kwargs_train['lindisp'] = args.lindisp\n",
    "\n",
    "    render_kwargs_test = {k : render_kwargs_train[k] for k in render_kwargs_train}\n",
    "    render_kwargs_test['perturb'] = False\n",
    "    render_kwargs_test['raw_noise_std'] = 0.\n",
    "\n",
    "    return render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce81b35",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f36d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    import os\n",
    "    import skimage\n",
    "    \"\"\"\n",
    "    End-to-end NeRF training loop.\n",
    "\n",
    "    High-level overview for newcomers:\n",
    "    - Load a dataset of posed images (e.g., LLFF/Blender/LINEMOD). Each image comes with a camera pose.\n",
    "    - Create a NeRF model (coarse and optionally fine MLPs) and a renderer.\n",
    "    - On each iteration, sample camera rays and their target RGB values from the dataset.\n",
    "    - Render rays with the NeRF model via volumetric rendering (accumulate colors along the ray).\n",
    "    - Compute a reconstruction loss (e.g., MSE) against ground-truth pixels and optimize the networks.\n",
    "    - Periodically render validation trajectories and/or save snapshots.\n",
    "\n",
    "    Key concepts:\n",
    "    - Rays: For each pixel, we cast a ray into the scene with origin/direction computed from intrinsics and pose.\n",
    "    - Sampling: We sample multiple points along each ray (coarse). Optionally resample (fine) where the scene is likely.\n",
    "    - Volume rendering: Convert per-point density+color to opacity weights and composite to a final pixel color.\n",
    "    - Hierarchical sampling: A second pass focuses samples where the coarse pass is confident the scene exists.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------\n",
    "    # 1) Load data and choose near/far bounds depending on dataset\n",
    "    # ----------------------\n",
    "    K = None\n",
    "    if args.dataset_type == 'llff':\n",
    "        images, poses, bds, render_poses, i_test = load_llff_data(\n",
    "            args.datadir, args.factor, recenter=True, bd_factor=.75, spherify=args.spherify\n",
    "        )\n",
    "        hwf = poses[0,:3,-1]           # (H, W, focal)\n",
    "        poses = poses[:,:3,:4]         # Only keep rotation+translation (3x4) per pose\n",
    "        print('Loaded llff', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        if not isinstance(i_test, list):\n",
    "            i_test = [i_test]\n",
    "\n",
    "        # Optional LLFF holdout: use every N-th image as test\n",
    "        if args.llffhold > 0:\n",
    "            print('Auto LLFF holdout,', args.llffhold)\n",
    "            i_test = np.arange(images.shape[0])[::args.llffhold]\n",
    "\n",
    "        i_val = i_test\n",
    "        i_train = np.array([i for i in np.arange(int(images.shape[0]))\n",
    "                            if (i not in i_test and i not in i_val)])\n",
    "\n",
    "        print('DEFINING BOUNDS')\n",
    "        if args.no_ndc:\n",
    "            # If not using NDC (e.g., inward-facing/360 scenes), near/far from bounds\n",
    "            near = np.ndarray.min(bds) * .9\n",
    "            far = np.ndarray.max(bds) * 1.\n",
    "        else:\n",
    "            # Forward-facing (LLFF) uses NDC, so near/far are normalized\n",
    "            near = 0.\n",
    "            far = 1.\n",
    "        print('NEAR FAR', near, far)\n",
    "\n",
    "    elif args.dataset_type == 'blender':\n",
    "        images, poses, render_poses, hwf, i_split = load_blender_data(\n",
    "            args.datadir, args.half_res, args.testskip\n",
    "        )\n",
    "        print('Loaded blender', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        # Standard near/far for Blender synthetic scenes\n",
    "        near = 2.\n",
    "        far = 6.\n",
    "\n",
    "        # Composite over white if requested (makes background white instead of black)\n",
    "        if args.white_bkgd:\n",
    "            images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "        else:\n",
    "            images = images[...,:3]\n",
    "\n",
    "    elif args.dataset_type == 'LINEMOD':\n",
    "        images, poses, render_poses, hwf, K, i_split, near, far = load_LINEMOD_data(\n",
    "            args.datadir, args.half_res, args.testskip\n",
    "        )\n",
    "        print(f'Loaded LINEMOD, images shape: {images.shape}, hwf: {hwf}, K: {K}')\n",
    "        print(f'[CHECK HERE] near: {near}, far: {far}.')\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        if args.white_bkgd:\n",
    "            images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "        else:\n",
    "            images = images[...,:3]\n",
    "\n",
    "    elif args.dataset_type == 'deepvoxels':\n",
    "        images, poses, render_poses, hwf, i_split = load_dv_data(\n",
    "            scene=args.shape, basedir=args.datadir, testskip=args.testskip\n",
    "        )\n",
    "        print('Loaded deepvoxels', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        # DeepVoxels scenes define a hemisphere radius; near/far around it\n",
    "        hemi_R = np.mean(np.linalg.norm(poses[:,:3,-1], axis=-1))\n",
    "        near = hemi_R-1.\n",
    "        far = hemi_R+1.\n",
    "\n",
    "    else:\n",
    "        print('Unknown dataset type', args.dataset_type, 'exiting')\n",
    "        return\n",
    "\n",
    "    # ----------------------\n",
    "    # 2) Prepare intrinsics (H, W, focal) and default K if not provided\n",
    "    # ----------------------\n",
    "    H, W, focal = hwf\n",
    "    H, W = int(H), int(W)\n",
    "    hwf = [H, W, focal]\n",
    "\n",
    "    if K is None:\n",
    "        # Construct a pinhole intrinsics matrix assuming principal point at image center\n",
    "        K = np.array([\n",
    "            [focal, 0, 0.5*W],\n",
    "            [0, focal, 0.5*H],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    # If we are evaluating on the test set, use the corresponding subset of poses\n",
    "    if args.render_test:\n",
    "        render_poses = np.array(poses[i_test])\n",
    "\n",
    "    # ----------------------\n",
    "    # 3) Logging setup and persistence of configs\n",
    "    # ----------------------\n",
    "    basedir = args.basedir\n",
    "    expname = args.expname\n",
    "    os.makedirs(os.path.join(basedir, expname), exist_ok=True)\n",
    "\n",
    "    # Save the parsed args for reproducibility\n",
    "    f = os.path.join(basedir, expname, 'args.txt')\n",
    "    with open(f, 'w') as file:\n",
    "        for arg, attr in sorted(args.items()):\n",
    "            attr = getattr(args, arg)\n",
    "            file.write('{} = {}\\n'.format(arg, attr))\n",
    "    # Save the YAML configuration that produced these args\n",
    "    f_yaml = os.path.join(basedir, expname, 'config.yaml')\n",
    "    try:\n",
    "        utils.save_yaml(dict(args), f_yaml)\n",
    "    except Exception:\n",
    "        # Fallback: write a simple YAML dump directly\n",
    "        with open(f_yaml, 'w', encoding='utf-8') as yf:\n",
    "            import yaml as _yaml\n",
    "            _yaml.dump(dict(args), yf, default_flow_style=False, indent=2)\n",
    "\n",
    "    # ----------------------\n",
    "    # 4) Create NeRF models and optimizer\n",
    "    # ----------------------\n",
    "    render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer = create_nerf(args)\n",
    "    global_step = start\n",
    "\n",
    "    # Near/far bounds are used by the renderer; update both train and test configs\n",
    "    bds_dict = { 'near' : near, 'far' : far }\n",
    "    render_kwargs_train.update(bds_dict)\n",
    "    render_kwargs_test.update(bds_dict)\n",
    "\n",
    "    # Move the camera trajectory used for rendering validation videos to the GPU\n",
    "    render_poses = torch.Tensor(render_poses).to(device)\n",
    "\n",
    "    # ----------------------\n",
    "    # 5) Short-circuit: render only mode\n",
    "    # ----------------------\n",
    "    if args.render_only:\n",
    "        print('RENDER ONLY')\n",
    "        with torch.no_grad():\n",
    "            if args.render_test:\n",
    "                # Switch to test poses\n",
    "                images = images[i_test]\n",
    "            else:\n",
    "                # Default is smoother render_poses path\n",
    "                images = None\n",
    "\n",
    "            testsavedir = os.path.join(\n",
    "                basedir, expname, 'renderonly_{}_{:06d}'.format('test' if args.render_test else 'path', start)\n",
    "            )\n",
    "            os.makedirs(testsavedir, exist_ok=True)\n",
    "            print('test poses shape', render_poses.shape)\n",
    "\n",
    "            # Render a path and save to video\n",
    "            rgbs, _ = render_path(render_poses, hwf, K, args.chunk, render_kwargs_test,\n",
    "                                   gt_imgs=images, savedir=testsavedir, render_factor=args.render_factor)\n",
    "            print('Done rendering', testsavedir)\n",
    "            imageio.mimwrite(os.path.join(testsavedir, 'video.mp4'), to8b(rgbs), fps=30, quality=8)\n",
    "\n",
    "            return\n",
    "\n",
    "    # ----------------------\n",
    "    # 6) Prepare random-ray batching (optional) and move data to GPU\n",
    "    # ----------------------\n",
    "    N_rand = args.N_rand\n",
    "    use_batching = not args.no_batching\n",
    "    if use_batching:\n",
    "        # Precompute all rays for all training images, then shuffle mini-batches each step\n",
    "        print('get rays')\n",
    "        rays = np.stack([get_rays_np(H, W, K, p) for p in poses[:,:3,:4]], 0)  # [N, ro+rd, H, W, 3]\n",
    "        print('done, concats')\n",
    "        rays_rgb = np.concatenate([rays, images[:,None]], 1)                   # [N, ro+rd+rgb, H, W, 3]\n",
    "        rays_rgb = np.transpose(rays_rgb, [0,2,3,1,4])                         # [N, H, W, ro+rd+rgb, 3]\n",
    "        rays_rgb = np.stack([rays_rgb[i] for i in i_train], 0)                 # train images only\n",
    "        rays_rgb = np.reshape(rays_rgb, [-1,3,3])                              # [(N-1)*H*W, ro+rd+rgb, 3]\n",
    "        rays_rgb = rays_rgb.astype(np.float32)\n",
    "        print('shuffle rays')\n",
    "        np.random.shuffle(rays_rgb)\n",
    "        print('done')\n",
    "        i_batch = 0\n",
    "\n",
    "    # Move arrays/tensors to GPU for training\n",
    "    if use_batching:\n",
    "        images = torch.Tensor(images).to(device)\n",
    "    poses = torch.Tensor(poses).to(device)\n",
    "    if use_batching:\n",
    "        rays_rgb = torch.Tensor(rays_rgb).to(device)\n",
    "\n",
    "    print('Begin')\n",
    "    print('TRAIN views are', i_train)\n",
    "    print('TEST views are', i_test)\n",
    "    print('VAL views are', i_val)\n",
    "\n",
    "    # ----------------------\n",
    "    # 7) Main optimization loop\n",
    "    # ----------------------\n",
    "    # writer = SummaryWriter(os.path.join(basedir, 'summaries', expname))  # Optional TB logging\n",
    "\n",
    "    start = start + 1\n",
    "    for i in trange(start, N_iters):\n",
    "        time0 = time.time()\n",
    "\n",
    "        # Ensure global step and loop iteration i are synced for checkpoint resume\n",
    "        global_step = i\n",
    "\n",
    "        # Sample a batch of rays and target colors\n",
    "        if use_batching:\n",
    "            # Random over all images (global batching)\n",
    "            batch = rays_rgb[i_batch:i_batch+N_rand]  # [B, 2+1, 3*?]\n",
    "            batch = torch.transpose(batch, 0, 1)\n",
    "            batch_rays, target_s = batch[:2], batch[2]\n",
    "\n",
    "            # Move sliding window; reshuffle at epoch end\n",
    "            i_batch += N_rand\n",
    "            if i_batch >= rays_rgb.shape[0]:\n",
    "                print(\"Shuffle data after an epoch!\")\n",
    "                rand_idx = torch.randperm(rays_rgb.shape[0])\n",
    "                rays_rgb = rays_rgb[rand_idx]\n",
    "                i_batch = 0\n",
    "        else:\n",
    "            # Random rays from a randomly chosen training image (per-image batching)\n",
    "            img_i = np.random.choice(i_train)\n",
    "            target = images[img_i]\n",
    "            target = torch.Tensor(target).to(device)\n",
    "            pose = poses[img_i, :3,:4]\n",
    "\n",
    "            if N_rand is not None:\n",
    "                # Compute per-pixel rays for this image, then sample N_rand of them\n",
    "                rays_o, rays_d = get_rays(H, W, K, torch.Tensor(pose))  # (H, W, 3), (H, W, 3)\n",
    "\n",
    "                if i < args.precrop_iters:\n",
    "                    # Optional: focus early training on the image center (stabilizes training)\n",
    "                    dH = int(H//2 * args.precrop_frac)\n",
    "                    dW = int(W//2 * args.precrop_frac)\n",
    "                    coords = torch.stack(\n",
    "                        torch.meshgrid(\n",
    "                            torch.linspace(H//2 - dH, H//2 + dH - 1, 2*dH), \n",
    "                            torch.linspace(W//2 - dW, W//2 + dW - 1, 2*dW)\n",
    "                        ), -1)\n",
    "                    if i == start:\n",
    "                        print(f\"[Config] Center cropping of size {2*dH} x {2*dW} is enabled until iter {args.precrop_iters}\")                \n",
    "                else:\n",
    "                    coords = torch.stack(\n",
    "                        torch.meshgrid(torch.linspace(0, H-1, H), torch.linspace(0, W-1, W)), -1\n",
    "                    )  # (H, W, 2)\n",
    "\n",
    "                coords = torch.reshape(coords, [-1,2])                         # (H*W, 2)\n",
    "                select_inds = np.random.choice(coords.shape[0], size=[N_rand], replace=False)  # (N_rand,)\n",
    "                select_coords = coords[select_inds].long()                     # (N_rand, 2)\n",
    "                rays_o = rays_o[select_coords[:, 0], select_coords[:, 1]]      # (N_rand, 3)\n",
    "                rays_d = rays_d[select_coords[:, 0], select_coords[:, 1]]      # (N_rand, 3)\n",
    "                batch_rays = torch.stack([rays_o, rays_d], 0)\n",
    "                target_s = target[select_coords[:, 0], select_coords[:, 1]]    # (N_rand, 3)\n",
    "\n",
    "        # ---- Core rendering + loss ----\n",
    "        rgb, disp, acc, extras = render(\n",
    "            H, W, K, chunk=args.chunk, rays=batch_rays, verbose=i < 10, retraw=True, **render_kwargs_train\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        img_loss = img2mse(rgb, target_s)\n",
    "        trans = extras['raw'][...,-1]\n",
    "        loss = img_loss\n",
    "        psnr = mse2psnr(img_loss)\n",
    "\n",
    "        # If hierarchical sampling is enabled, include the coarse-pass loss\n",
    "        if 'rgb0' in extras:\n",
    "            img_loss0 = img2mse(extras['rgb0'], target_s)\n",
    "            loss = loss + img_loss0\n",
    "            psnr0 = mse2psnr(img_loss0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- Learning rate decay (exponential) ---\n",
    "        decay_rate = 0.1\n",
    "        decay_steps = args.lrate_decay * 1000\n",
    "        new_lrate = args.lrate * (decay_rate ** (global_step / decay_steps))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = new_lrate\n",
    "\n",
    "        dt = time.time()-time0\n",
    "        # print(f\"Step: {global_step}, Loss: {loss}, Time: {dt}\")\n",
    "\n",
    "        # ----------------------\n",
    "        # 8) Periodic logging, checkpointing, and visualization\n",
    "        # ----------------------\n",
    "        if i%args.i_weights==0:\n",
    "            # Save model checkpoints for resuming or analysis\n",
    "            path = os.path.join(basedir, expname, \"checkpoints\" ,'{:06d}.tar'.format(i))\n",
    "            torch.save({\n",
    "                'global_step': global_step,\n",
    "                'network_fn_state_dict': render_kwargs_train['network_fn'].state_dict(),\n",
    "                'network_fine_state_dict': render_kwargs_train['network_fine'].state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, path)\n",
    "            print('Saved checkpoints at', path)\n",
    "\n",
    "        if i%args.i_video==0 and i > 0:\n",
    "            # Render a validation trajectory and write MP4 previews\n",
    "            with torch.no_grad():\n",
    "                rgbs, disps = render_path(render_poses, hwf, K, args.chunk, render_kwargs_test)\n",
    "            print('Done, saving', rgbs.shape, disps.shape)\n",
    "            moviebase = os.path.join(basedir, expname, '{}_spiral_{:06d}_'.format(expname, i))\n",
    "            imageio.mimwrite(moviebase + 'rgb.mp4', to8b(rgbs), fps=30, quality=8)\n",
    "            imageio.mimwrite(moviebase + 'disp.mp4', to8b(disps / np.max(disps)), fps=30, quality=8)\n",
    "\n",
    "            # If you want to visualize view-dependent effects, you can fix the camera position\n",
    "            # and vary only the view direction (see commented example in original code).\n",
    "\n",
    "        if i%args.i_testset==0 and i > 0:\n",
    "            # Render the held-out test set and save frames with comprehensive metrics\n",
    "            testsavedir = os.path.join(basedir, expname, 'testset_{:06d}'.format(i))\n",
    "            os.makedirs(testsavedir, exist_ok=True)\n",
    "\n",
    "            # Make metrics dir to store our metrics\n",
    "            metricsdir = os.path.join(basedir, expname, \"metrics\")\n",
    "            os.makedirs(metricsdir, exist_ok=True)\n",
    "            print('test poses shape', poses[i_test].shape)\n",
    "            \n",
    "            # Calculate whether to include LPIPS (slower, so maybe every 3rd evaluation)\n",
    "            # Count how many test evaluations we've done\n",
    "            test_eval_count = i // args.i_testset\n",
    "            # include_lpips = (test_eval_count % 3 == 0)  # Every 3rd test evaluation\n",
    "            include_lpips = True  # use true for now as its not that bad = the computation\n",
    "                        \n",
    "\n",
    "            # Alternative: Always include LPIPS (comment out above and uncomment below)\n",
    "            # include_lpips = True\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    # Enhanced render with metrics calculation\n",
    "                    rgbs, disps, metrics = render_path(\n",
    "                        torch.Tensor(poses[i_test]).to(device), hwf, K, args.chunk,\n",
    "                        render_kwargs_test, \n",
    "                        gt_imgs=images[i_test], \n",
    "                        savedir=testsavedir,\n",
    "                        calculate_metrics=True,\n",
    "                        metrics_include_lpips=include_lpips,\n",
    "                        metrics_device=device\n",
    "                    )\n",
    "                    \n",
    "                    # Log metrics to both TXT and JSON formats\n",
    "                    import json\n",
    "                    import time as time_module\n",
    "                    \n",
    "                    # Text format (human readable)\n",
    "                    metrics_file_txt = os.path.join(basedir, expname, \"metrics\", f'metrics_{i:06d}.txt')\n",
    "                    with open(metrics_file_txt, 'w') as f:\n",
    "                        f.write(f\"Iteration: {i}\\n\")\n",
    "                        f.write(f\"Timestamp: {time_module.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                        f.write(f\"LPIPS_included: {include_lpips}\\n\")\n",
    "                        f.write(\"-\" * 40 + \"\\n\")\n",
    "                        for key, value in metrics.items():\n",
    "                            f.write(f\"{key}: {value:.6f}\\n\")\n",
    "                    \n",
    "                    # JSON format (machine readable)\n",
    "                    metrics_file_json = os.path.join(basedir, expname, \"metrics\", f'metrics_{i:06d}.json')\n",
    "                    json_data = {\n",
    "                        'iteration': i,\n",
    "                        'timestamp': time_module.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'lpips_included': include_lpips,\n",
    "                        'metrics': {k: float(v) for k, v in metrics.items()}\n",
    "                    }\n",
    "                    with open(metrics_file_json, 'w') as f:\n",
    "                        json.dump(json_data, f, indent=2)\n",
    "                    \n",
    "                    # Append to consolidated training log\n",
    "                    training_log_file = os.path.join(basedir, expname, \"metrics\", 'training_metrics.json')\n",
    "                    if os.path.exists(training_log_file):\n",
    "                        with open(training_log_file, 'r') as f:\n",
    "                            training_log = json.load(f)\n",
    "                    else:\n",
    "                        training_log = {'experiment': expname, 'metrics_history': []}\n",
    "                    \n",
    "                    training_log['metrics_history'].append(json_data)\n",
    "                    with open(training_log_file, 'w') as f:\n",
    "                        json.dump(training_log, f, indent=2)\n",
    "                    \n",
    "                    print(f\"Metrics logged to: {metrics_file_txt} and {metrics_file_json}\")\n",
    "                    print(f\"Training history updated: {training_log_file}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Enhanced evaluation failed, using basic render: {e}\")\n",
    "                    # Fallback to basic rendering\n",
    "                    render_path(torch.Tensor(poses[i_test]).to(device), hwf, K, args.chunk,\n",
    "                               render_kwargs_test, gt_imgs=images[i_test], savedir=testsavedir)\n",
    "            \n",
    "            print('Saved test set with metrics')\n",
    "\n",
    "        if i%args.i_print==0:\n",
    "            tqdm.write(f\"[TRAIN] Iter: {i} Loss: {loss.item()}  PSNR: {psnr.item()}\")\n",
    "            \n",
    "            import json\n",
    "            import time as time_module\n",
    "            \n",
    "            # Save detailed training log\n",
    "            training_data = {\n",
    "                'iteration': i,\n",
    "                'timestamp': time_module.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'loss': float(loss.item()),\n",
    "                'psnr': float(psnr.item()),\n",
    "                'learning_rate': optimizer.param_groups[0]['lr']\n",
    "            }\n",
    "            \n",
    "            # Add coarse loss if available\n",
    "            if 'rgb0' in extras:\n",
    "                training_data['loss_coarse'] = float(img_loss0.item())\n",
    "                training_data['psnr_coarse'] = float(psnr0.item())\n",
    "            \n",
    "            # Append to training log file\n",
    "            training_log_file = os.path.join(basedir, expname, 'training_log.jsonl')\n",
    "            with open(training_log_file, 'a') as f:\n",
    "                f.write(json.dumps(training_data) + '\\n')\n",
    "            \n",
    "            # Also save as CSV for easy analysis\n",
    "            csv_log_file = os.path.join(basedir, expname, 'training_log.csv')\n",
    "            import os\n",
    "            if not os.path.exists(csv_log_file):\n",
    "                # Create header\n",
    "                with open(csv_log_file, 'w') as f:\n",
    "                    headers = ['iteration', 'timestamp', 'loss', 'psnr', 'learning_rate']\n",
    "                    if 'rgb0' in extras:\n",
    "                        headers.extend(['loss_coarse', 'psnr_coarse'])\n",
    "                    f.write(','.join(headers) + '\\n')\n",
    "            \n",
    "            # Append data\n",
    "            with open(csv_log_file, 'a') as f:\n",
    "                row_data = [str(training_data[key]) for key in ['iteration', 'timestamp', 'loss', 'psnr', 'learning_rate']]\n",
    "                if 'rgb0' in extras:\n",
    "                    row_data.extend([str(training_data['loss_coarse']), str(training_data['psnr_coarse'])])\n",
    "                f.write(','.join(row_data) + '\\n')\n",
    "\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac403e",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c482509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded blender (138, 800, 800, 4) torch.Size([40, 4, 4]) [800, 800, np.float64(1111.1110311937682)] ./data/nerf_synthetic/ship\n",
      "Found ckpts []\n",
      "Not ndc!\n",
      "Begin\n",
      "TRAIN views are [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n",
      "TEST views are [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137]\n",
      "VAL views are [100 101 102 103 104 105 106 107 108 109 110 111 112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config] Center cropping of size 400 x 400 is enabled until iter 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\nerf-projects\\nerf\\.venv\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4324.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  1%|          | 1001/200000 [02:29<8:07:48,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 1000 Loss: 0.02703813463449478  PSNR: 18.873912811279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2001/200000 [04:59<8:12:16,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 2000 Loss: 0.014134297147393227  PSNR: 21.651899337768555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3001/200000 [07:31<8:11:59,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 3000 Loss: 0.011281629092991352  PSNR: 22.807647705078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4001/200000 [10:02<8:28:59,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 4000 Loss: 0.011225137859582901  PSNR: 22.735225677490234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5001/200000 [12:34<8:02:10,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 5000 Loss: 0.009835847653448582  PSNR: 23.127941131591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6001/200000 [15:05<8:42:35,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 6000 Loss: 0.010197076946496964  PSNR: 23.46279525756836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7001/200000 [17:36<8:16:19,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 7000 Loss: 0.008184758946299553  PSNR: 24.578683853149414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8001/200000 [20:08<7:58:23,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 8000 Loss: 0.014123108237981796  PSNR: 22.141983032226562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 9001/200000 [22:41<7:49:26,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 9000 Loss: 0.00782245397567749  PSNR: 24.787160873413086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10001/200000 [25:12<8:32:09,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\010000.tar\n",
      "[TRAIN] Iter: 10000 Loss: 0.011145872995257378  PSNR: 23.285533905029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11001/200000 [27:43<7:47:11,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 11000 Loss: 0.009289225563406944  PSNR: 24.767581939697266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12001/200000 [30:14<7:43:59,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 12000 Loss: 0.007449848111718893  PSNR: 24.514026641845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 13001/200000 [32:45<7:57:48,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 13000 Loss: 0.011484567075967789  PSNR: 23.209569931030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14001/200000 [35:16<8:02:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 14000 Loss: 0.008831962943077087  PSNR: 24.231021881103516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15001/200000 [37:48<7:32:48,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 15000 Loss: 0.008566387929022312  PSNR: 24.492753982543945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16001/200000 [40:13<7:23:44,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 16000 Loss: 0.006082460284233093  PSNR: 26.032611846923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 17001/200000 [42:40<7:52:11,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 17000 Loss: 0.005529690533876419  PSNR: 25.723543167114258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18001/200000 [45:16<7:45:11,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 18000 Loss: 0.009225727058947086  PSNR: 24.037626266479492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19001/200000 [47:55<7:42:04,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 19000 Loss: 0.0064555564895272255  PSNR: 25.290658950805664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20001/200000 [50:31<7:45:04,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\020000.tar\n",
      "[TRAIN] Iter: 20000 Loss: 0.007642399985343218  PSNR: 25.073627471923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 21001/200000 [53:05<7:28:22,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 21000 Loss: 0.008661126717925072  PSNR: 23.899343490600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22001/200000 [55:40<7:32:09,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 22000 Loss: 0.006721525453031063  PSNR: 25.82712173461914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23001/200000 [58:15<7:25:54,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 23000 Loss: 0.006798615679144859  PSNR: 25.714977264404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24001/200000 [1:00:47<7:22:56,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 24000 Loss: 0.006691374816000462  PSNR: 25.345914840698242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 25001/200000 [1:03:20<7:22:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 25000 Loss: 0.006233075633645058  PSNR: 25.451080322265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26001/200000 [1:05:55<7:29:08,  6.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 26000 Loss: 0.007812762632966042  PSNR: 24.991661071777344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27001/200000 [1:08:31<7:16:44,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 27000 Loss: 0.007583301514387131  PSNR: 24.596891403198242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28001/200000 [1:11:05<7:19:42,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 28000 Loss: 0.005594450980424881  PSNR: 25.93825340270996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 29001/200000 [1:13:39<7:05:16,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 29000 Loss: 0.00743396021425724  PSNR: 25.54022789001465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30001/200000 [1:16:15<7:31:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\030000.tar\n",
      "[TRAIN] Iter: 30000 Loss: 0.009090022183954716  PSNR: 24.051387786865234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31001/200000 [1:18:49<7:33:21,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 31000 Loss: 0.00683456240221858  PSNR: 25.557044982910156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32001/200000 [1:21:23<7:00:57,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 32000 Loss: 0.006219794042408466  PSNR: 27.061830520629883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 33001/200000 [1:23:56<7:07:11,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 33000 Loss: 0.0047484394162893295  PSNR: 26.7652530670166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34001/200000 [1:26:30<6:59:31,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 34000 Loss: 0.0061880131252110004  PSNR: 26.12705421447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35001/200000 [1:29:06<7:39:04,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 35000 Loss: 0.006873925216495991  PSNR: 25.015981674194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36001/200000 [1:31:38<6:54:38,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 36000 Loss: 0.005809767637401819  PSNR: 26.616756439208984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 37001/200000 [1:34:12<6:58:51,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 37000 Loss: 0.0067953369580209255  PSNR: 25.560213088989258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38001/200000 [1:36:47<6:56:25,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 38000 Loss: 0.0037822378799319267  PSNR: 29.009016036987305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39001/200000 [1:39:22<6:55:46,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 39000 Loss: 0.005900314077734947  PSNR: 26.393186569213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40001/200000 [1:41:57<6:57:10,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\040000.tar\n",
      "[TRAIN] Iter: 40000 Loss: 0.005269918590784073  PSNR: 26.161104202270508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 41001/200000 [1:44:32<6:47:42,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 41000 Loss: 0.004055521450936794  PSNR: 27.665876388549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42001/200000 [1:47:06<6:43:09,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 42000 Loss: 0.006109561771154404  PSNR: 26.07720375061035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43001/200000 [1:49:40<6:40:07,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 43000 Loss: 0.004919724073261023  PSNR: 27.10034942626953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44001/200000 [1:52:13<6:33:58,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 44000 Loss: 0.003904170822352171  PSNR: 27.770381927490234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 45001/200000 [1:54:44<6:27:38,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 45000 Loss: 0.004818654619157314  PSNR: 27.465129852294922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46001/200000 [1:57:16<6:35:19,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 46000 Loss: 0.007608301937580109  PSNR: 25.171993255615234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47001/200000 [1:59:49<6:24:17,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 47000 Loss: 0.0053566559217870235  PSNR: 27.49433708190918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48001/200000 [2:02:21<6:25:28,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 48000 Loss: 0.004898060578852892  PSNR: 26.850053787231445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 49001/200000 [2:04:55<6:30:41,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 49000 Loss: 0.004556602798402309  PSNR: 27.519981384277344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 49999/200000 [2:07:28<6:27:24,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\050000.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.002465486526489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "1 40.88119888305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 43.27020215988159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 40.609182357788086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 41.454001903533936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 41.036882400512695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 40.43398904800415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 41.32930397987366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 42.12748384475708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 40.67503499984741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 40.24250674247742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 40.7868332862854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 40.83236241340637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 40.65360188484192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 40.72481942176819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 40.47212195396423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 40.89969205856323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 42.912891149520874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 43.043986082077026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 39.01219701766968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 39.00898313522339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 38.6578323841095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 38.74339437484741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 38.92628788948059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 39.355818033218384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 39.31734848022461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 38.8914897441864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 38.735692739486694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 38.548213720321655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 38.80468201637268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 38.95731329917908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 38.803335428237915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 38.953521490097046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 36.83932185173035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 30.932189226150513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 30.931474447250366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 30.972352743148804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 30.979562759399414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 30.945709705352783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 30.96122121810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [25:40<00:00, 38.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0023288726806640625\n",
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\nerf-projects\\nerf\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\GitHub\\nerf-projects\\nerf\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: d:\\GitHub\\nerf-projects\\nerf\\.venv\\Lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "Frame 0 - PSNR: 26.45, SSIM: 0.7505, LPIPS: 0.3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 33.08561110496521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1 - PSNR: 25.70, SSIM: 0.7451, LPIPS: 0.2963\n",
      "2 31.01781463623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 2 - PSNR: 25.81, SSIM: 0.7514, LPIPS: 0.2872\n",
      "3 31.003568410873413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 3 - PSNR: 26.07, SSIM: 0.7571, LPIPS: 0.2949\n",
      "4 31.05986523628235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 4 - PSNR: 26.57, SSIM: 0.7894, LPIPS: 0.2756\n",
      "5 31.03875470161438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 5 - PSNR: 26.31, SSIM: 0.8123, LPIPS: 0.2701\n",
      "6 31.06104564666748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 6 - PSNR: 25.48, SSIM: 0.8167, LPIPS: 0.2681\n",
      "7 31.044384002685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 7 - PSNR: 25.64, SSIM: 0.8220, LPIPS: 0.2619\n",
      "8 31.03125762939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 8 - PSNR: 26.04, SSIM: 0.8298, LPIPS: 0.2548\n",
      "9 31.021644115447998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 9 - PSNR: 26.88, SSIM: 0.8552, LPIPS: 0.2275\n",
      "10 31.069543600082397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 10 - PSNR: 27.09, SSIM: 0.8718, LPIPS: 0.2135\n",
      "11 31.054287433624268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 11 - PSNR: 25.64, SSIM: 0.8563, LPIPS: 0.2207\n",
      "12 31.019580125808716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 12 - PSNR: 24.67, SSIM: 0.8506, LPIPS: 0.2254\n",
      "13 31.040910243988037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 13 - PSNR: 24.75, SSIM: 0.8555, LPIPS: 0.2131\n",
      "14 31.040313482284546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 14 - PSNR: 24.98, SSIM: 0.8711, LPIPS: 0.1967\n",
      "15 31.023792028427124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 15 - PSNR: 26.25, SSIM: 0.8842, LPIPS: 0.1818\n",
      "16 30.9947988986969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 16 - PSNR: 26.59, SSIM: 0.8690, LPIPS: 0.1926\n",
      "17 31.038219690322876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 17 - PSNR: 25.59, SSIM: 0.8438, LPIPS: 0.2246\n",
      "18 31.048261404037476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 18 - PSNR: 25.17, SSIM: 0.8277, LPIPS: 0.2508\n",
      "19 31.0466468334198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 19 - PSNR: 25.56, SSIM: 0.8163, LPIPS: 0.2695\n",
      "20 31.04893207550049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 20 - PSNR: 25.94, SSIM: 0.8155, LPIPS: 0.2787\n",
      "21 31.081602811813354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 21 - PSNR: 26.47, SSIM: 0.8109, LPIPS: 0.2901\n",
      "22 31.063095569610596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 22 - PSNR: 27.26, SSIM: 0.8166, LPIPS: 0.2960\n",
      "23 31.03350806236267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 23 - PSNR: 27.44, SSIM: 0.7969, LPIPS: 0.2993\n",
      "24 31.05296277999878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:58<00:00, 31.12s/it]\n",
      " 25%|██▌       | 50000/200000 [2:46:08<29004:12:00, 696.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 24 - PSNR: 27.08, SSIM: 0.7709, LPIPS: 0.3040\n",
      "\n",
      "=== METRICS SUMMARY ===\n",
      "Average PSNR: 26.0580 ± 0.7502\n",
      "Average SSIM: 0.8195 ± 0.0402\n",
      "Average LPIPS: 0.2560 ± 0.0378\n",
      "=======================\n",
      "Metrics logged to: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_050000.txt and ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_050000.json\n",
      "Training history updated: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\training_metrics.json\n",
      "Saved test set with metrics\n",
      "[TRAIN] Iter: 50000 Loss: 0.0059603676199913025  PSNR: 26.013748168945312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51001/200000 [2:48:33<6:00:03,  6.90it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 51000 Loss: 0.004183984361588955  PSNR: 27.86517333984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52001/200000 [2:50:58<5:56:31,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 52000 Loss: 0.005671474151313305  PSNR: 26.84699821472168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 53001/200000 [2:53:23<5:55:57,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 53000 Loss: 0.005463732406497002  PSNR: 26.86399269104004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54001/200000 [2:55:47<5:50:54,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 54000 Loss: 0.007277948781847954  PSNR: 24.842395782470703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55001/200000 [2:58:12<5:49:56,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 55000 Loss: 0.006327393464744091  PSNR: 26.081729888916016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56001/200000 [3:00:56<7:07:46,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 56000 Loss: 0.005565634462982416  PSNR: 26.498062133789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 57001/200000 [3:03:50<6:43:48,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 57000 Loss: 0.004488984122872353  PSNR: 27.517047882080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58001/200000 [3:06:43<6:18:23,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 58000 Loss: 0.004457986447960138  PSNR: 27.28682518005371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59001/200000 [3:09:37<6:37:28,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 59000 Loss: 0.005672221537679434  PSNR: 26.301687240600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60001/200000 [3:12:33<6:30:53,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\060000.tar\n",
      "[TRAIN] Iter: 60000 Loss: 0.005299689713865519  PSNR: 25.9290714263916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 61001/200000 [3:15:27<6:17:38,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 61000 Loss: 0.0034662147518247366  PSNR: 29.236658096313477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62001/200000 [3:18:22<6:54:14,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 62000 Loss: 0.006179520394653082  PSNR: 26.815662384033203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63001/200000 [3:21:16<6:21:09,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 63000 Loss: 0.0054740216583013535  PSNR: 26.925926208496094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64001/200000 [3:24:07<6:44:41,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 64000 Loss: 0.0063876016065478325  PSNR: 25.552223205566406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 65001/200000 [3:26:47<5:37:29,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 65000 Loss: 0.0045754555612802505  PSNR: 27.557844161987305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66001/200000 [3:29:19<5:37:46,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 66000 Loss: 0.005206495523452759  PSNR: 26.645606994628906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67001/200000 [3:31:51<5:37:38,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 67000 Loss: 0.0062256911769509315  PSNR: 25.81958770751953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68001/200000 [3:34:22<5:32:16,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 68000 Loss: 0.007164039183408022  PSNR: 25.84735107421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 69001/200000 [3:36:48<5:13:38,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 69000 Loss: 0.006812990177422762  PSNR: 25.72471046447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70001/200000 [3:39:13<5:21:03,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\070000.tar\n",
      "[TRAIN] Iter: 70000 Loss: 0.003460866864770651  PSNR: 28.90595054626465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71001/200000 [3:41:38<5:11:03,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 71000 Loss: 0.004611298441886902  PSNR: 27.09161949157715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72001/200000 [3:44:02<5:08:07,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 72000 Loss: 0.005645987577736378  PSNR: 27.0596981048584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 73001/200000 [3:46:29<5:40:05,  6.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 73000 Loss: 0.004724087193608284  PSNR: 27.32999610900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74001/200000 [3:49:05<5:19:56,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 74000 Loss: 0.004790063481777906  PSNR: 26.808561325073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75001/200000 [3:51:36<5:11:56,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 75000 Loss: 0.004232112318277359  PSNR: 26.97902488708496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76001/200000 [3:54:08<5:07:01,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 76000 Loss: 0.003962992690503597  PSNR: 28.582544326782227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 77001/200000 [3:56:40<5:07:45,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 77000 Loss: 0.00432491023093462  PSNR: 27.444311141967773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78001/200000 [3:59:05<4:54:29,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 78000 Loss: 0.004715759307146072  PSNR: 26.948135375976562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79001/200000 [4:01:47<5:13:03,  6.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 79000 Loss: 0.006067204289138317  PSNR: 25.645503997802734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80001/200000 [4:04:33<5:30:06,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\080000.tar\n",
      "[TRAIN] Iter: 80000 Loss: 0.005264965817332268  PSNR: 26.582971572875977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 81001/200000 [4:07:24<5:36:57,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 81000 Loss: 0.0037454338744282722  PSNR: 27.578296661376953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82001/200000 [4:10:11<5:10:24,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 82000 Loss: 0.003791513154283166  PSNR: 28.663330078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83001/200000 [4:12:58<5:12:28,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 83000 Loss: 0.005584012717008591  PSNR: 27.08004379272461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84000/200000 [4:15:48<6:53:36,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 84000 Loss: 0.0037321432027965784  PSNR: 28.517854690551758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 85001/200000 [4:18:34<4:52:35,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 85000 Loss: 0.004698870703577995  PSNR: 27.492204666137695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86001/200000 [4:21:06<4:49:46,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 86000 Loss: 0.004388880450278521  PSNR: 27.60680389404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87001/200000 [4:23:39<4:42:46,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 87000 Loss: 0.005548551212996244  PSNR: 26.585208892822266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88001/200000 [4:26:12<4:45:28,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 88000 Loss: 0.003921864554286003  PSNR: 28.011751174926758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 89001/200000 [4:28:42<4:25:28,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 89000 Loss: 0.005814752541482449  PSNR: 26.63813018798828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90001/200000 [4:31:07<4:32:36,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\090000.tar\n",
      "[TRAIN] Iter: 90000 Loss: 0.004889360163360834  PSNR: 27.557025909423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91001/200000 [4:33:33<4:22:51,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 91000 Loss: 0.004020638298243284  PSNR: 27.598478317260742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92001/200000 [4:35:58<4:20:16,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 92000 Loss: 0.004967436194419861  PSNR: 27.380260467529297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 93001/200000 [4:38:24<4:17:10,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 93000 Loss: 0.004180189222097397  PSNR: 27.860538482666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94001/200000 [4:40:49<4:17:28,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 94000 Loss: 0.005019684787839651  PSNR: 27.49823760986328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95001/200000 [4:43:15<4:13:43,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 95000 Loss: 0.004387437365949154  PSNR: 27.43877601623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96001/200000 [4:45:40<4:11:26,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 96000 Loss: 0.005791021510958672  PSNR: 26.420804977416992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 97001/200000 [4:48:06<4:08:51,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 97000 Loss: 0.004057193174958229  PSNR: 28.04981231689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98001/200000 [4:50:31<4:05:37,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 98000 Loss: 0.004707618150860071  PSNR: 27.164663314819336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99001/200000 [4:52:56<4:03:35,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 99000 Loss: 0.003807329572737217  PSNR: 28.421049118041992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99999/200000 [4:55:21<4:03:28,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\100000.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0023279190063476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "1 31.067312002182007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 30.954099416732788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 30.975966453552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 30.894644021987915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 30.945509672164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 30.93149447441101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 30.971210956573486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 30.95546865463257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 30.92339301109314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 30.96631622314453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 30.946157217025757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 30.96176528930664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 30.925667762756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 30.97114133834839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 30.963400840759277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 30.94664764404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 30.981507301330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 30.95962953567505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 30.933119297027588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 30.979862213134766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 30.977850437164307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 30.919346570968628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 30.919600009918213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 30.962496042251587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 30.95562505722046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 30.95115065574646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 30.9310142993927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 30.938868522644043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 30.935879945755005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30.945950746536255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 30.944103717803955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 30.985987663269043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 30.92332673072815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 30.966848373413086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 30.939285278320312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 30.93383765220642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 30.935628175735474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 30.952829122543335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 30.919214725494385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [20:38<00:00, 30.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0019288063049316406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "Frame 0 - PSNR: 27.21, SSIM: 0.7698, LPIPS: 0.2687\n",
      "1 31.06692385673523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1 - PSNR: 26.40, SSIM: 0.7641, LPIPS: 0.2633\n",
      "2 31.0062096118927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 2 - PSNR: 26.77, SSIM: 0.7733, LPIPS: 0.2574\n",
      "3 31.042542934417725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 3 - PSNR: 26.70, SSIM: 0.7718, LPIPS: 0.2665\n",
      "4 31.04079794883728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 4 - PSNR: 27.47, SSIM: 0.8033, LPIPS: 0.2466\n",
      "5 31.030628204345703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 5 - PSNR: 27.36, SSIM: 0.8283, LPIPS: 0.2379\n",
      "6 31.058279275894165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 6 - PSNR: 26.47, SSIM: 0.8326, LPIPS: 0.2416\n",
      "7 31.022740602493286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 7 - PSNR: 26.46, SSIM: 0.8373, LPIPS: 0.2346\n",
      "8 30.99923038482666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 8 - PSNR: 26.95, SSIM: 0.8450, LPIPS: 0.2282\n",
      "9 31.029686212539673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 9 - PSNR: 27.53, SSIM: 0.8654, LPIPS: 0.2085\n",
      "10 31.039998054504395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 10 - PSNR: 27.87, SSIM: 0.8827, LPIPS: 0.1947\n",
      "11 31.045485734939575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 11 - PSNR: 26.44, SSIM: 0.8670, LPIPS: 0.2008\n",
      "12 31.0511155128479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 12 - PSNR: 25.32, SSIM: 0.8609, LPIPS: 0.2133\n",
      "13 31.038606643676758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 13 - PSNR: 25.44, SSIM: 0.8675, LPIPS: 0.1998\n",
      "14 31.00075387954712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 14 - PSNR: 25.78, SSIM: 0.8855, LPIPS: 0.1791\n",
      "15 31.04326367378235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 15 - PSNR: 27.16, SSIM: 0.8977, LPIPS: 0.1652\n",
      "16 31.049798488616943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 16 - PSNR: 27.70, SSIM: 0.8829, LPIPS: 0.1744\n",
      "17 31.04252862930298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 17 - PSNR: 26.72, SSIM: 0.8606, LPIPS: 0.2008\n",
      "18 31.05394434928894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 18 - PSNR: 26.13, SSIM: 0.8428, LPIPS: 0.2270\n",
      "19 31.044567108154297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 19 - PSNR: 26.46, SSIM: 0.8315, LPIPS: 0.2468\n",
      "20 31.065054655075073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 20 - PSNR: 26.80, SSIM: 0.8315, LPIPS: 0.2497\n",
      "21 31.06117057800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 21 - PSNR: 27.31, SSIM: 0.8247, LPIPS: 0.2619\n",
      "22 31.060892820358276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 22 - PSNR: 28.12, SSIM: 0.8283, LPIPS: 0.2703\n",
      "23 31.04687261581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 23 - PSNR: 28.23, SSIM: 0.8107, LPIPS: 0.2666\n",
      "24 31.04159426689148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:56<00:00, 31.04s/it]\n",
      " 50%|█████     | 100000/200000 [5:28:57<16795:26:46, 604.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 24 - PSNR: 27.85, SSIM: 0.7872, LPIPS: 0.2712\n",
      "\n",
      "=== METRICS SUMMARY ===\n",
      "Average PSNR: 26.9064 ± 0.7650\n",
      "Average SSIM: 0.8341 ± 0.0383\n",
      "Average LPIPS: 0.2310 ± 0.0323\n",
      "=======================\n",
      "Metrics logged to: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_100000.txt and ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_100000.json\n",
      "Training history updated: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\training_metrics.json\n",
      "Saved test set with metrics\n",
      "[TRAIN] Iter: 100000 Loss: 0.006200630217790604  PSNR: 25.94236183166504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 101001/200000 [5:31:22<3:54:37,  7.03it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 101000 Loss: 0.004293335601687431  PSNR: 28.03034019470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102001/200000 [5:33:47<3:56:06,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 102000 Loss: 0.004541709553450346  PSNR: 27.728885650634766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103001/200000 [5:36:12<3:51:54,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 103000 Loss: 0.005602912046015263  PSNR: 27.224464416503906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 104001/200000 [5:38:37<3:54:54,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 104000 Loss: 0.005136994179338217  PSNR: 27.343841552734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 105001/200000 [5:41:02<3:49:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 105000 Loss: 0.005217303521931171  PSNR: 27.183639526367188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106001/200000 [5:43:28<3:45:35,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 106000 Loss: 0.005177712999284267  PSNR: 26.86688232421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107001/200000 [5:45:53<3:45:11,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 107000 Loss: 0.005254107061773539  PSNR: 27.506122589111328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108001/200000 [5:48:18<3:41:26,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 108000 Loss: 0.005350267514586449  PSNR: 26.895803451538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109001/200000 [5:50:44<3:37:46,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 109000 Loss: 0.0042017241939902306  PSNR: 27.819011688232422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110001/200000 [5:53:09<3:43:27,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\110000.tar\n",
      "[TRAIN] Iter: 110000 Loss: 0.004724619444459677  PSNR: 27.157394409179688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111001/200000 [5:55:34<3:32:14,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 111000 Loss: 0.004086778499186039  PSNR: 27.698928833007812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112001/200000 [5:58:00<3:30:46,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 112000 Loss: 0.004201927687972784  PSNR: 27.80699348449707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 113001/200000 [6:00:25<3:28:11,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 113000 Loss: 0.005704249255359173  PSNR: 26.449321746826172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 114001/200000 [6:02:50<3:26:10,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 114000 Loss: 0.003693635342642665  PSNR: 28.82670021057129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 115001/200000 [6:05:15<3:24:34,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 115000 Loss: 0.003365281270816922  PSNR: 28.542797088623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 116001/200000 [6:07:40<3:22:57,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 116000 Loss: 0.003482447238638997  PSNR: 29.210186004638672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 117001/200000 [6:10:05<3:19:29,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 117000 Loss: 0.0029746186919510365  PSNR: 28.838104248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 118001/200000 [6:12:30<3:16:09,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 118000 Loss: 0.004618261009454727  PSNR: 27.615617752075195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119001/200000 [6:14:55<3:14:09,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 119000 Loss: 0.004182604141533375  PSNR: 27.446109771728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120001/200000 [6:17:20<3:14:30,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\120000.tar\n",
      "[TRAIN] Iter: 120000 Loss: 0.0033258101902902126  PSNR: 28.137081146240234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 121001/200000 [6:19:45<3:09:02,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 121000 Loss: 0.005257769487798214  PSNR: 26.686174392700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 122001/200000 [6:22:10<3:06:35,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 122000 Loss: 0.004072974435985088  PSNR: 28.23678207397461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 123001/200000 [6:24:35<3:02:55,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 123000 Loss: 0.005924940574914217  PSNR: 25.961015701293945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 124001/200000 [6:27:00<3:02:38,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 124000 Loss: 0.006723129190504551  PSNR: 26.560293197631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 125001/200000 [6:29:25<2:59:31,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 125000 Loss: 0.005099298898130655  PSNR: 26.432092666625977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 126001/200000 [6:31:50<2:57:35,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 126000 Loss: 0.003798385849222541  PSNR: 28.47818374633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127001/200000 [6:34:15<2:56:48,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 127000 Loss: 0.003936982713639736  PSNR: 27.715106964111328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 128001/200000 [6:36:40<2:52:33,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 128000 Loss: 0.0053092110902071  PSNR: 25.600801467895508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 129001/200000 [6:39:05<2:49:19,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 129000 Loss: 0.0043903132900595665  PSNR: 27.51958465576172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130001/200000 [6:41:30<2:51:38,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\130000.tar\n",
      "[TRAIN] Iter: 130000 Loss: 0.0034678212832659483  PSNR: 28.968069076538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131001/200000 [6:43:55<2:46:01,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 131000 Loss: 0.004328851122409105  PSNR: 27.67096519470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 132001/200000 [6:46:20<2:42:11,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 132000 Loss: 0.003102600108832121  PSNR: 29.176959991455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 133001/200000 [6:48:45<2:41:25,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 133000 Loss: 0.0050847032107412815  PSNR: 27.284000396728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 134001/200000 [6:51:10<2:40:13,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 134000 Loss: 0.004374898970127106  PSNR: 27.908533096313477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 135001/200000 [6:53:35<2:35:36,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 135000 Loss: 0.005114286672323942  PSNR: 27.246885299682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136001/200000 [6:56:00<2:34:30,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 136000 Loss: 0.003604557830840349  PSNR: 28.379344940185547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 137001/200000 [6:58:24<2:32:41,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 137000 Loss: 0.007415123283863068  PSNR: 25.73487663269043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 138001/200000 [7:00:49<2:29:17,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 138000 Loss: 0.004053005017340183  PSNR: 28.71807289123535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 139001/200000 [7:03:14<2:27:26,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 139000 Loss: 0.005127715412527323  PSNR: 26.724227905273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140001/200000 [7:05:40<2:26:22,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\140000.tar\n",
      "[TRAIN] Iter: 140000 Loss: 0.00598546490073204  PSNR: 26.82205581665039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 141001/200000 [7:08:05<2:22:39,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 141000 Loss: 0.003824398387223482  PSNR: 28.304418563842773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 142001/200000 [7:10:30<2:20:03,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 142000 Loss: 0.004684159532189369  PSNR: 27.607040405273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 143001/200000 [7:12:55<2:16:52,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 143000 Loss: 0.003374851308763027  PSNR: 28.495933532714844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 144001/200000 [7:15:20<2:14:59,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 144000 Loss: 0.005234038457274437  PSNR: 26.15675926208496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 145001/200000 [7:17:45<2:12:19,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 145000 Loss: 0.004058373160660267  PSNR: 27.85353660583496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 146001/200000 [7:20:10<2:09:43,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 146000 Loss: 0.003911430481821299  PSNR: 27.908241271972656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 147001/200000 [7:22:35<2:08:24,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 147000 Loss: 0.0035303495824337006  PSNR: 30.09024429321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 148001/200000 [7:25:00<2:05:50,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 148000 Loss: 0.004676308482885361  PSNR: 26.844482421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 149001/200000 [7:27:25<2:03:56,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 149000 Loss: 0.005103479139506817  PSNR: 26.629369735717773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 149999/200000 [7:29:50<2:00:29,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\150000.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0016825199127197266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "1 31.02525806427002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 30.896987676620483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 30.927396535873413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 30.943825483322144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 30.925148248672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 30.967805862426758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 30.907572269439697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 30.946932315826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 30.925058364868164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 30.911763429641724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 30.93995213508606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 30.930694341659546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 30.941697120666504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 30.938517093658447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 30.879674911499023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 30.904196977615356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 30.943002700805664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 30.93690037727356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 30.92060613632202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 30.94822907447815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 30.93238115310669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 30.971762895584106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 30.926698923110962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 30.920185327529907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 30.86725354194641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 30.932913303375244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 30.884018659591675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 30.910454273223877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 30.930466413497925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30.905494213104248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 30.902165174484253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 30.91347622871399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 30.91509985923767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 30.919166803359985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 30.957637071609497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 30.919461011886597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 30.909079790115356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 30.929067850112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 30.926214694976807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [20:37<00:00, 30.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0020101070404052734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "Frame 0 - PSNR: 27.72, SSIM: 0.7808, LPIPS: 0.2513\n",
      "1 31.058589458465576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1 - PSNR: 26.87, SSIM: 0.7761, LPIPS: 0.2446\n",
      "2 31.008776426315308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 2 - PSNR: 27.28, SSIM: 0.7870, LPIPS: 0.2398\n",
      "3 31.033056497573853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 3 - PSNR: 27.06, SSIM: 0.7796, LPIPS: 0.2504\n",
      "4 30.99478316307068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 4 - PSNR: 27.89, SSIM: 0.8101, LPIPS: 0.2326\n",
      "5 31.027581691741943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 5 - PSNR: 27.93, SSIM: 0.8360, LPIPS: 0.2241\n",
      "6 31.058845043182373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 6 - PSNR: 26.99, SSIM: 0.8404, LPIPS: 0.2294\n",
      "7 30.989991903305054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 7 - PSNR: 27.14, SSIM: 0.8451, LPIPS: 0.2237\n",
      "8 30.987743139266968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 8 - PSNR: 27.56, SSIM: 0.8516, LPIPS: 0.2198\n",
      "9 31.048692226409912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 9 - PSNR: 28.22, SSIM: 0.8712, LPIPS: 0.1984\n",
      "10 31.00091791152954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 10 - PSNR: 28.58, SSIM: 0.8882, LPIPS: 0.1866\n",
      "11 31.00019359588623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 11 - PSNR: 26.85, SSIM: 0.8722, LPIPS: 0.1908\n",
      "12 31.00786566734314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 12 - PSNR: 25.79, SSIM: 0.8685, LPIPS: 0.1987\n",
      "13 30.960247039794922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 13 - PSNR: 25.92, SSIM: 0.8748, LPIPS: 0.1871\n",
      "14 30.990488052368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 14 - PSNR: 26.16, SSIM: 0.8933, LPIPS: 0.1670\n",
      "15 31.000401973724365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 15 - PSNR: 27.78, SSIM: 0.9059, LPIPS: 0.1501\n",
      "16 31.02807092666626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 16 - PSNR: 28.24, SSIM: 0.8893, LPIPS: 0.1634\n",
      "17 31.059220552444458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 17 - PSNR: 27.33, SSIM: 0.8675, LPIPS: 0.1886\n",
      "18 31.00451683998108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 18 - PSNR: 26.65, SSIM: 0.8498, LPIPS: 0.2158\n",
      "19 31.019503355026245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 19 - PSNR: 27.03, SSIM: 0.8388, LPIPS: 0.2321\n",
      "20 31.002334356307983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 20 - PSNR: 27.44, SSIM: 0.8394, LPIPS: 0.2384\n",
      "21 31.024771690368652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 21 - PSNR: 27.85, SSIM: 0.8318, LPIPS: 0.2494\n",
      "22 31.027872562408447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 22 - PSNR: 28.69, SSIM: 0.8350, LPIPS: 0.2563\n",
      "23 31.016927480697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 23 - PSNR: 28.82, SSIM: 0.8182, LPIPS: 0.2510\n",
      "24 31.03699827194214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:55<00:00, 31.02s/it]\n",
      " 75%|███████▌  | 150000/200000 [8:03:23<8391:34:32, 604.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 24 - PSNR: 28.34, SSIM: 0.7956, LPIPS: 0.2522\n",
      "\n",
      "=== METRICS SUMMARY ===\n",
      "Average PSNR: 27.4455 ± 0.8058\n",
      "Average SSIM: 0.8418 ± 0.0371\n",
      "Average LPIPS: 0.2177 ± 0.0307\n",
      "=======================\n",
      "Metrics logged to: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_150000.txt and ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_150000.json\n",
      "Training history updated: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\training_metrics.json\n",
      "Saved test set with metrics\n",
      "[TRAIN] Iter: 150000 Loss: 0.00398494815453887  PSNR: 27.997238159179688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151001/200000 [8:05:48<1:56:48,  6.99it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 151000 Loss: 0.003865275764837861  PSNR: 28.621103286743164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 152001/200000 [8:08:13<1:55:26,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 152000 Loss: 0.00553170358762145  PSNR: 26.91531753540039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 153001/200000 [8:10:38<1:53:22,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 153000 Loss: 0.0040213847532868385  PSNR: 27.622180938720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 154001/200000 [8:13:03<1:52:08,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 154000 Loss: 0.007591934408992529  PSNR: 25.109071731567383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155001/200000 [8:15:29<1:48:22,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 155000 Loss: 0.004640092607587576  PSNR: 26.759418487548828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156001/200000 [8:17:53<1:45:04,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 156000 Loss: 0.005853986367583275  PSNR: 26.86829376220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 157001/200000 [8:20:18<1:43:54,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 157000 Loss: 0.0036208939272910357  PSNR: 28.123624801635742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158001/200000 [8:22:43<1:40:43,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 158000 Loss: 0.0036833910271525383  PSNR: 28.043729782104492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159001/200000 [8:25:08<1:38:20,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 159000 Loss: 0.002436238806694746  PSNR: 30.589113235473633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160001/200000 [8:27:34<1:39:55,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\160000.tar\n",
      "[TRAIN] Iter: 160000 Loss: 0.003257605480030179  PSNR: 28.250001907348633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 161001/200000 [8:30:01<1:38:06,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 161000 Loss: 0.003677332540974021  PSNR: 28.748178482055664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 162001/200000 [8:32:38<1:36:55,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 162000 Loss: 0.00447121262550354  PSNR: 27.009580612182617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163001/200000 [8:35:13<1:34:40,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 163000 Loss: 0.002999486867338419  PSNR: 30.199893951416016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 164001/200000 [8:37:48<1:33:24,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 164000 Loss: 0.006042309571057558  PSNR: 26.753955841064453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 165001/200000 [8:40:23<1:28:22,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 165000 Loss: 0.004785830620676279  PSNR: 27.620893478393555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 166001/200000 [8:42:40<1:16:30,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 166000 Loss: 0.002842977875843644  PSNR: 29.517826080322266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 167001/200000 [8:44:56<1:14:10,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 167000 Loss: 0.0034402606543153524  PSNR: 28.39792823791504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 168001/200000 [8:47:12<1:12:21,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 168000 Loss: 0.0031167897395789623  PSNR: 29.389673233032227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 169001/200000 [8:49:28<1:09:41,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 169000 Loss: 0.004837749991565943  PSNR: 27.95529556274414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170001/200000 [8:51:45<1:09:29,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\170000.tar\n",
      "[TRAIN] Iter: 170000 Loss: 0.00473704794421792  PSNR: 26.953365325927734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171001/200000 [8:54:01<1:05:09,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 171000 Loss: 0.003300874261185527  PSNR: 29.717453002929688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 172001/200000 [8:56:17<1:02:51,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 172000 Loss: 0.00472907442599535  PSNR: 29.180816650390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 173001/200000 [8:58:33<1:01:08,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 173000 Loss: 0.004728070460259914  PSNR: 27.274417877197266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 174001/200000 [9:00:50<59:21,  7.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 174000 Loss: 0.0035652623046189547  PSNR: 28.630290985107422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 175001/200000 [9:03:06<56:56,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 175000 Loss: 0.004304095171391964  PSNR: 28.187604904174805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 176001/200000 [9:05:22<53:49,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 176000 Loss: 0.005350832361727953  PSNR: 26.895156860351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 177001/200000 [9:07:38<52:24,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 177000 Loss: 0.00293621513992548  PSNR: 29.601482391357422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 178001/200000 [9:09:54<49:37,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 178000 Loss: 0.005099562928080559  PSNR: 27.016246795654297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 179001/200000 [9:12:11<47:03,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 179000 Loss: 0.005641625262796879  PSNR: 27.078336715698242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180001/200000 [9:14:27<46:06,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\180000.tar\n",
      "[TRAIN] Iter: 180000 Loss: 0.0036047559697180986  PSNR: 28.67751121520996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 181001/200000 [9:16:43<43:01,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 181000 Loss: 0.0036166564095765352  PSNR: 28.236404418945312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 182001/200000 [9:19:00<40:44,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 182000 Loss: 0.005110572092235088  PSNR: 27.15743064880371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183001/200000 [9:21:16<38:34,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 183000 Loss: 0.003563643665984273  PSNR: 28.190204620361328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 184001/200000 [9:23:32<36:08,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 184000 Loss: 0.0045555355027318  PSNR: 28.257755279541016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 185001/200000 [9:25:49<33:55,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 185000 Loss: 0.004909185692667961  PSNR: 27.040857315063477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 186001/200000 [9:28:05<31:35,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 186000 Loss: 0.0033997236751019955  PSNR: 28.71727752685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 187001/200000 [9:30:21<29:19,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 187000 Loss: 0.004810669459402561  PSNR: 27.781835556030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 188001/200000 [9:32:38<26:56,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 188000 Loss: 0.005122028291225433  PSNR: 27.942386627197266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 189001/200000 [9:34:54<24:55,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 189000 Loss: 0.0038134329952299595  PSNR: 28.857641220092773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190001/200000 [9:37:10<22:54,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\190000.tar\n",
      "[TRAIN] Iter: 190000 Loss: 0.0039069755002856255  PSNR: 27.968833923339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 191001/200000 [9:39:27<20:19,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 191000 Loss: 0.0030521138105541468  PSNR: 29.804264068603516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 192001/200000 [9:41:43<17:59,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 192000 Loss: 0.003878558985888958  PSNR: 29.060653686523438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 193001/200000 [9:43:59<15:53,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 193000 Loss: 0.004135563038289547  PSNR: 28.201889038085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194001/200000 [9:46:16<13:30,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 194000 Loss: 0.002895652549341321  PSNR: 29.027353286743164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 195001/200000 [9:48:32<11:17,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 195000 Loss: 0.003973056562244892  PSNR: 27.85625457763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 196001/200000 [9:50:49<09:03,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 196000 Loss: 0.003619161434471607  PSNR: 28.851978302001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 197001/200000 [9:53:05<06:52,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 197000 Loss: 0.004476785659790039  PSNR: 27.302406311035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 198001/200000 [9:55:21<04:32,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 198000 Loss: 0.0028619635850191116  PSNR: 29.365449905395508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199001/200000 [9:57:38<02:15,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 199000 Loss: 0.00480707036331296  PSNR: 27.200193405151367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199999/200000 [9:59:54<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints at ./logs\\ship_blender200k_fullres_higher_samples\\checkpoints\\200000.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0017039775848388672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "1 29.001757621765137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 28.97565245628357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 29.01278829574585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 29.001259088516235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 29.00534224510193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 32.92943215370178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 29.738768339157104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 29.389034032821655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 29.392902135849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 29.39199924468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 29.392184019088745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 29.413095712661743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 29.40765905380249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 29.405179262161255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 29.409266233444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 29.402910709381104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 29.399266004562378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 29.03937602043152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 29.0261709690094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 29.040441751480103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 29.03043794631958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 29.0256404876709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 29.017939567565918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 29.045901775360107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 29.02931833267212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 29.042506217956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 29.034425735473633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 29.040652990341187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29.03409719467163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 29.04183578491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 29.03053879737854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 30.384079933166504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 35.53028655052185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 29.37862539291382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 29.389444589614868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 29.383774757385254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 29.37813115119934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 29.377781867980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 29.37355089187622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [19:39<00:00, 29.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.001956462860107422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 3]) torch.Size([800, 800])\n",
      "Frame 0 - PSNR: 28.02, SSIM: 0.7883, LPIPS: 0.2417\n",
      "1 29.540377616882324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1 - PSNR: 27.17, SSIM: 0.7843, LPIPS: 0.2324\n",
      "2 29.50209069252014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 2 - PSNR: 27.62, SSIM: 0.7957, LPIPS: 0.2296\n",
      "3 29.597777128219604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 3 - PSNR: 27.25, SSIM: 0.7855, LPIPS: 0.2415\n",
      "4 29.121036529541016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 4 - PSNR: 28.12, SSIM: 0.8145, LPIPS: 0.2249\n",
      "5 29.15498638153076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 5 - PSNR: 28.27, SSIM: 0.8416, LPIPS: 0.2140\n",
      "6 29.15734052658081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 6 - PSNR: 27.31, SSIM: 0.8461, LPIPS: 0.2199\n",
      "7 29.12328815460205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 7 - PSNR: 27.46, SSIM: 0.8513, LPIPS: 0.2130\n",
      "8 29.129096508026123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 8 - PSNR: 27.97, SSIM: 0.8574, LPIPS: 0.2088\n",
      "9 29.120907068252563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 9 - PSNR: 28.58, SSIM: 0.8746, LPIPS: 0.1945\n",
      "10 29.111916542053223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 10 - PSNR: 28.86, SSIM: 0.8913, LPIPS: 0.1823\n",
      "11 29.130505323410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 11 - PSNR: 26.99, SSIM: 0.8749, LPIPS: 0.1859\n",
      "12 29.13886857032776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 12 - PSNR: 26.05, SSIM: 0.8718, LPIPS: 0.1883\n",
      "13 29.137919664382935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 13 - PSNR: 26.06, SSIM: 0.8789, LPIPS: 0.1771\n",
      "14 29.136210441589355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 14 - PSNR: 26.54, SSIM: 0.8974, LPIPS: 0.1571\n",
      "15 29.151644468307495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 15 - PSNR: 28.12, SSIM: 0.9103, LPIPS: 0.1445\n",
      "16 29.13982105255127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 16 - PSNR: 28.62, SSIM: 0.8947, LPIPS: 0.1558\n",
      "17 29.10737442970276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 17 - PSNR: 27.59, SSIM: 0.8731, LPIPS: 0.1789\n",
      "18 29.126954555511475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 18 - PSNR: 26.81, SSIM: 0.8535, LPIPS: 0.2065\n",
      "19 29.138595819473267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 19 - PSNR: 27.36, SSIM: 0.8447, LPIPS: 0.2211\n",
      "20 29.147693634033203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 20 - PSNR: 27.83, SSIM: 0.8455, LPIPS: 0.2293\n",
      "21 29.157140016555786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 21 - PSNR: 28.16, SSIM: 0.8367, LPIPS: 0.2391\n",
      "22 29.147220134735107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 22 - PSNR: 28.99, SSIM: 0.8386, LPIPS: 0.2456\n",
      "23 29.126991987228394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 23 - PSNR: 29.10, SSIM: 0.8227, LPIPS: 0.2430\n",
      "24 29.151573419570923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:09<00:00, 29.19s/it]\n",
      "100%|██████████| 200000/200000 [10:31:44<00:00,  5.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 24 - PSNR: 28.50, SSIM: 0.8001, LPIPS: 0.2466\n",
      "\n",
      "=== METRICS SUMMARY ===\n",
      "Average PSNR: 27.7337 ± 0.8293\n",
      "Average SSIM: 0.8469 ± 0.0361\n",
      "Average LPIPS: 0.2089 ± 0.0299\n",
      "=======================\n",
      "Metrics logged to: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_200000.txt and ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\metrics_200000.json\n",
      "Training history updated: ./logs\\ship_blender200k_fullres_higher_samples\\metrics\\training_metrics.json\n",
      "Saved test set with metrics\n",
      "[TRAIN] Iter: 200000 Loss: 0.003799606580287218  PSNR: 29.015316009521484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert training parameters\n",
    "N_iters = 200000 + 1\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
